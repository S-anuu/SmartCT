{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":52254,"databundleVersionId":9674523,"sourceType":"competition"},{"sourceId":12242890,"sourceType":"datasetVersion","datasetId":7713895},{"sourceId":12245224,"sourceType":"datasetVersion","datasetId":7715503},{"sourceId":12245232,"sourceType":"datasetVersion","datasetId":7715507},{"sourceId":12245569,"sourceType":"datasetVersion","datasetId":7715459},{"sourceId":12247149,"sourceType":"datasetVersion","datasetId":7715595},{"sourceId":12247192,"sourceType":"datasetVersion","datasetId":7715723},{"sourceId":12247822,"sourceType":"datasetVersion","datasetId":7716931},{"sourceId":12248019,"sourceType":"datasetVersion","datasetId":7717359},{"sourceId":12248026,"sourceType":"datasetVersion","datasetId":7717019},{"sourceId":12248216,"sourceType":"datasetVersion","datasetId":7717073},{"sourceId":12248344,"sourceType":"datasetVersion","datasetId":7716417},{"sourceId":12248429,"sourceType":"datasetVersion","datasetId":7717311},{"sourceId":12248555,"sourceType":"datasetVersion","datasetId":7717450},{"sourceId":12248570,"sourceType":"datasetVersion","datasetId":7717422},{"sourceId":12248642,"sourceType":"datasetVersion","datasetId":7717550},{"sourceId":12248646,"sourceType":"datasetVersion","datasetId":7717525},{"sourceId":12248817,"sourceType":"datasetVersion","datasetId":7717528},{"sourceId":12248822,"sourceType":"datasetVersion","datasetId":7717451},{"sourceId":12248899,"sourceType":"datasetVersion","datasetId":7717562},{"sourceId":12248924,"sourceType":"datasetVersion","datasetId":7717559},{"sourceId":12248941,"sourceType":"datasetVersion","datasetId":7717513},{"sourceId":12248986,"sourceType":"datasetVersion","datasetId":7717737},{"sourceId":12249017,"sourceType":"datasetVersion","datasetId":7717764},{"sourceId":12249031,"sourceType":"datasetVersion","datasetId":7717797},{"sourceId":12249087,"sourceType":"datasetVersion","datasetId":7717809},{"sourceId":12249259,"sourceType":"datasetVersion","datasetId":7717907},{"sourceId":12249263,"sourceType":"datasetVersion","datasetId":7717914},{"sourceId":12249332,"sourceType":"datasetVersion","datasetId":7717947},{"sourceId":12249364,"sourceType":"datasetVersion","datasetId":7717984},{"sourceId":12249398,"sourceType":"datasetVersion","datasetId":7717979},{"sourceId":12249401,"sourceType":"datasetVersion","datasetId":7717995},{"sourceId":12249507,"sourceType":"datasetVersion","datasetId":7718311},{"sourceId":12249579,"sourceType":"datasetVersion","datasetId":7718001},{"sourceId":12249711,"sourceType":"datasetVersion","datasetId":7717756},{"sourceId":12249730,"sourceType":"datasetVersion","datasetId":7718247},{"sourceId":12249734,"sourceType":"datasetVersion","datasetId":7718243},{"sourceId":12250069,"sourceType":"datasetVersion","datasetId":7717555},{"sourceId":12250080,"sourceType":"datasetVersion","datasetId":7717565},{"sourceId":12250358,"sourceType":"datasetVersion","datasetId":7718213},{"sourceId":12250425,"sourceType":"datasetVersion","datasetId":7718208},{"sourceId":12250577,"sourceType":"datasetVersion","datasetId":7718838},{"sourceId":12250614,"sourceType":"datasetVersion","datasetId":7718879},{"sourceId":12251815,"sourceType":"datasetVersion","datasetId":7719516},{"sourceId":12252028,"sourceType":"datasetVersion","datasetId":7717569},{"sourceId":12275973,"sourceType":"datasetVersion","datasetId":7718258},{"sourceId":12276921,"sourceType":"datasetVersion","datasetId":7736108},{"sourceId":12276982,"sourceType":"datasetVersion","datasetId":7736025},{"sourceId":12277537,"sourceType":"datasetVersion","datasetId":7736720},{"sourceId":12277584,"sourceType":"datasetVersion","datasetId":7736693},{"sourceId":12277591,"sourceType":"datasetVersion","datasetId":7736109},{"sourceId":12277608,"sourceType":"datasetVersion","datasetId":7736643},{"sourceId":12277881,"sourceType":"datasetVersion","datasetId":7737297},{"sourceId":12278371,"sourceType":"datasetVersion","datasetId":7736402},{"sourceId":12353207,"sourceType":"datasetVersion","datasetId":7788050},{"sourceId":12354850,"sourceType":"datasetVersion","datasetId":7783903},{"sourceId":12367618,"sourceType":"datasetVersion","datasetId":7797751},{"sourceId":12391906,"sourceType":"datasetVersion","datasetId":7806772},{"sourceId":12394220,"sourceType":"datasetVersion","datasetId":7815599},{"sourceId":12409743,"sourceType":"datasetVersion","datasetId":7816725},{"sourceId":12411129,"sourceType":"datasetVersion","datasetId":7826844},{"sourceId":12427644,"sourceType":"datasetVersion","datasetId":7828526},{"sourceId":12431443,"sourceType":"datasetVersion","datasetId":7841460},{"sourceId":12445275,"sourceType":"datasetVersion","datasetId":7841446},{"sourceId":12458767,"sourceType":"datasetVersion","datasetId":7850616},{"sourceId":12478589,"sourceType":"datasetVersion","datasetId":7862658},{"sourceId":12482330,"sourceType":"datasetVersion","datasetId":7873460},{"sourceId":12482519,"sourceType":"datasetVersion","datasetId":7876168},{"sourceId":12497492,"sourceType":"datasetVersion","datasetId":7876761},{"sourceId":12505345,"sourceType":"datasetVersion","datasetId":7889431},{"sourceId":12507797,"sourceType":"datasetVersion","datasetId":7894462},{"sourceId":12512637,"sourceType":"datasetVersion","datasetId":7894468},{"sourceId":12520714,"sourceType":"datasetVersion","datasetId":7897891},{"sourceId":12540826,"sourceType":"datasetVersion","datasetId":7917294},{"sourceId":12551865,"sourceType":"datasetVersion","datasetId":7917596},{"sourceId":12564796,"sourceType":"datasetVersion","datasetId":7928101},{"sourceId":12575315,"sourceType":"datasetVersion","datasetId":7938644},{"sourceId":12587915,"sourceType":"datasetVersion","datasetId":7950249},{"sourceId":12595375,"sourceType":"datasetVersion","datasetId":7951582},{"sourceId":12667726,"sourceType":"datasetVersion","datasetId":8005197}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Environment Setup <a name=\"environment-setup\"></a>","metadata":{}},{"cell_type":"code","source":"# Install Kaggle API for dataset access\n!pip install kaggle --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install required libraries for medical image processing and deep learning\ntry:\n    import pydicom, nibabel, monai, SimpleITK, torchio\nexcept ImportError:\n    !pip install -q pydicom nibabel monai SimpleITK torchio\n    \n# Import standard libraries\nimport os\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n\n# Import medical image processing libraries\nimport pydicom\nimport nibabel as nib\nimport SimpleITK as sitk\n\n# Import PyTorch and MONAI for deep learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom monai.networks.nets import DenseNet121\nfrom monai.transforms import (\n    Compose, EnsureChannelFirst, EnsureType,\n    Orientation, Spacing, RandAffine, RandFlip,\n    NormalizeIntensity, RandScaleIntensity, RandShiftIntensity,\n    RandGaussianNoise, RandGaussianSmooth, RandAdjustContrast,\n    Resize, RandBiasField, ToTensor\n)\nfrom monai.data import MetaTensor\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\nset_seed()\n\n# Set device (GPU if available, else CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint(\"Environment setup complete.\")\n\n# Additional imports for file operations\nimport shutil\nimport zipfile\nfrom datetime import datetime\nfrom kaggle.api.kaggle_api_extended import KaggleApi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:20:24.898213Z","iopub.execute_input":"2025-08-04T10:20:24.898485Z","iopub.status.idle":"2025-08-04T10:22:36.085636Z","shell.execute_reply.started":"2025-08-04T10:20:24.898459Z","shell.execute_reply":"2025-08-04T10:22:36.084788Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-08-04 10:22:19.163699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754302939.537587      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754302939.642771      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"cuda\nEnvironment setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Data Preparation <a name=\"data-preparation\"></a>","metadata":{}},{"cell_type":"code","source":"# Set up Kaggle authentication\nos.makedirs(\"/root/.config/kaggle\", exist_ok=True)\nshutil.copy(\"/kaggle/input/kaggle-json/kaggle.json\", \"/root/.config/kaggle/kaggle.json\")\nos.chmod(\"/root/.config/kaggle/kaggle.json\", 0o600)\n\n# Initialize Kaggle API\napi = KaggleApi()\napi.authenticate()\n\n# Define dataset paths\nDATASET_ROOTS = [\n'/kaggle/input/abdominal-nifti-0-100',\n    '/kaggle/input/abdominal-nifti-100-200',\n    '/kaggle/input/abdominal-trauma-nifti-200-300',\n    '/kaggle/input/abdominal-trauma-nifti-300-400',\n    '/kaggle/input/abdominal-trauma-nifti-400-500',\n    '/kaggle/input/abdominal-trauma-nifti-500-600',\n    '/kaggle/input/abdominal-trauma-nifti-600-700',\n    '/kaggle/input/abdominal-trauma-nifti-700-800',\n    '/kaggle/input/abdominal-trauma-nifti-800-900',\n    '/kaggle/input/abdominal-trauma-nifti-900-1000',\n    \n    '/kaggle/input/abdominal-nifti-1000-1100',\n    '/kaggle/input/abdominal-nifti-1100-1200',\n    '/kaggle/input/abdominal-nifti-1200-1300',\n    '/kaggle/input/abdominal-nifti-1300-1400',\n    '/kaggle/input/abdominal-nifti-1400-1500',\n    '/kaggle/input/abdominal-nifti-1500-1600',\n    '/kaggle/input/abdominal-nifti-1600-1700',\n    '/kaggle/input/abdominal-nifti-1700-1800',\n    '/kaggle/input/abdominal-nifti-1800-1900',\n    '/kaggle/input/abdominal-nifti-1900-2000',\n    \n    '/kaggle/input/abdominal-trauma-nifti-2000-above',\n    '/kaggle/input/abdominal-nifti-2100-2150',\n    '/kaggle/input/abdominal-trauma-nifti-2230-2360',\n    '/kaggle/input/abdominal-trauma-nifti-2300-2400',\n    '/kaggle/input/abdominal-trauma-nifti-2400-2500',\n    '/kaggle/input/abdominal-trauma-nifti-2500-2600',\n    '/kaggle/input/abdominal-trauma-nifti-2600-2700',\n    '/kaggle/input/abdominal-trauma-nifti-2700-2800',\n    '/kaggle/input/abdominal-trauma-nifti-2800-2900',\n    '/kaggle/input/abdominal-trauma-nifti-2900-3000',\n\n    '/kaggle/input/abdominal-trauma-nifti-3000-3100',\n    '/kaggle/input/abdominal-trauma-nifti-3100-3200',\n    '/kaggle/input/abdominal-trauma-nifti-3200-3300',\n    '/kaggle/input/abdominal-trauma-nifti-3300-3400',\n    '/kaggle/input/abdominal-trauma-nifti-3400-3500',\n    '/kaggle/input/abdominal-trauma-nifti-3500-3600',\n    '/kaggle/input/abdominal-trauma-nifti-3600-3700',\n    '/kaggle/input/abdominal-trauma-nifti-3700-3800',\n    '/kaggle/input/abdominal-trauma-nifti-3800-3900',\n    '/kaggle/input/abdominal-trauma-nifti-3900-4000',\n\n    '/kaggle/input/abdominal-trauma-nifti-4000-4100',\n    '/kaggle/input/abdominal-trauma-nifti-4100-4200',\n    '/kaggle/input/abdominal-trauma-nifti-4200-4300',\n    '/kaggle/input/abdominal-nifti-4290-4400',\n    '/kaggle/input/abdominal-nifti-4380-4470',\n    '/kaggle/input/abdominal-nifti-4470-4560',\n    '/kaggle/input/abdominal-nifti-4560-4650',\n    '/kaggle/input/abdominal-nifti-4650-4710',  \n]\n\nLABELS_CSV_PATH = '/kaggle/input/rsna-2023-abdominal-trauma-detection/train_2024.csv'\nOUTPUT_JSON_PATH = '/kaggle/working/train_metadata.json'\n\n# Load and process labels\nlabels_df = pd.read_csv(LABELS_CSV_PATH)\nlabels_df['patient_id'] = labels_df['patient_id'].astype(str)\nlabels_dict_map = labels_df.set_index('patient_id').to_dict(orient='index')\nlabel_cols = [col for col in labels_df.columns if col != 'patient_id']\n\n# Create metadata dictionary for all NIfTI files\nmetadata_list = []\n\nfor dataset_root in DATASET_ROOTS:\n    nifti_files = sorted(Path(dataset_root).rglob(\"*.nii*\"))  # .nii or .nii.gz\n    \n    print(f\"Found {len(nifti_files)} NIfTI files in {dataset_root}\")\n    \n    for nii_path in nifti_files:\n        stem = nii_path.stem  # e.g. \"12345_67890\"\n        try:\n            patient_id, study_id = stem.split(\"_\")\n        except ValueError:\n            print(f\"Skipping malformed filename: {stem}\")\n            continue\n            \n        if patient_id not in labels_dict_map:\n            print(f\"No label for patient {patient_id}, skipping...\")\n            continue\n            \n        labels = {col: int(labels_dict_map[patient_id][col]) for col in label_cols}\n        \n        metadata_list.append({\n            \"patient_id\": patient_id,\n            \"study_id\": study_id,\n            \"nifti_path\": str(nii_path),\n            \"labels\": labels\n        })\n\nprint(f\"Total metadata entries: {len(metadata_list)}\")\n\n# Save metadata to JSON\nwith open(OUTPUT_JSON_PATH, 'w') as f:\n    json.dump(metadata_list, f, indent=2)\n    \nprint(f\"Metadata saved to {OUTPUT_JSON_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:36.086678Z","iopub.execute_input":"2025-08-04T10:22:36.087763Z","iopub.status.idle":"2025-08-04T10:22:36.560668Z","shell.execute_reply.started":"2025-08-04T10:22:36.087712Z","shell.execute_reply":"2025-08-04T10:22:36.560074Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Data Exploration <a name=\"data-exploration\"></a>","metadata":{}},{"cell_type":"code","source":"# Check for duplicate entries\nwith open(OUTPUT_JSON_PATH, \"r\") as f:\n    data = json.load(f)\n    \nid_pairs = [(entry[\"patient_id\"], entry[\"study_id\"]) for entry in data]\npair_counts = Counter(id_pairs)\nduplicates = [pair for pair, count in pair_counts.items() if count > 1]\n\nif duplicates:\n    print(f\"Found {len(duplicates)} duplicate entries:\")\n    for pair in duplicates:\n        print(f\" - patient_id: {pair[0]}, study_id: {pair[1]}\")\nelse:\n    print(\"No duplicate (patient_id, study_id) entries found.\")\n\n# Analyze class distribution\nlabel_rows = []\nfor entry in metadata_list:\n    row = entry[\"labels\"]\n    label_rows.append(row)\n    \nlabels_df = pd.DataFrame(label_rows)\n\n# Aggregate counts per label\nlabels_agg = pd.DataFrame({\n    'bowel_healthy': [labels_df['bowel_healthy'].sum()],\n    'bowel_injury': [labels_df['bowel_injury'].sum()],\n    'extravasation_healthy': [labels_df['extravasation_healthy'].sum()],\n    'extravasation_injury': [labels_df['extravasation_injury'].sum()],\n    \n    'kidney_healthy': [labels_df['kidney_healthy'].sum()],\n    'kidney_low': [labels_df['kidney_low'].sum()],\n    'kidney_high': [labels_df['kidney_high'].sum()],\n    \n    'liver_healthy': [labels_df['liver_healthy'].sum()],\n    'liver_low': [labels_df['liver_low'].sum()],\n    'liver_high': [labels_df['liver_high'].sum()],\n    \n    'spleen_healthy': [labels_df['spleen_healthy'].sum()],\n    'spleen_low': [labels_df['spleen_low'].sum()],\n    'spleen_high': [labels_df['spleen_high'].sum()]\n})\n\n# Prepare for plotting\nlabels_agg = labels_agg.T.reset_index()\nlabels_agg.columns = ['label', 'count']\nlabels_agg[['organ', 'status']] = labels_agg['label'].str.rsplit('_', n=1, expand=True)\n\n# Print counts\nprint(\"Counts per class:\")\nprint(labels_agg[['label', 'count']].to_string(index=False))\n\n# Create pivot table for visualization\npivot_df = labels_agg.pivot(index='organ', columns='status', values='count').fillna(0)\nstatus_order = ['healthy', 'injury', 'low', 'high']\nfor status in status_order:\n    if status not in pivot_df.columns:\n        pivot_df[status] = 0\npivot_df = pivot_df[status_order]\n\n# Plot class distribution\ncolor_map = {\n    'healthy': 'skyblue',\n    'low': 'orange',\n    'high': 'salmon',\n    'injury': 'red'\n}\ncolors = [color_map[status] for status in pivot_df.columns]\n\npivot_df.plot(kind='bar', figsize=(10, 6), color=colors)\nplt.title(\"Organ Injury Severity Distribution\")\nplt.ylabel(\"Number of Samples\")\nplt.xlabel(\"Organ\")\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.legend(title='Status')\nplt.tight_layout()\nplt.show()\n\n# Analyze injury vs healthy distribution\nlabels_df['injury_status'] = labels_df['any_injury'].apply(lambda x: 'injured' if x == 1 else 'healthy')\nstatus_counts = labels_df['injury_status'].value_counts()\n\nprint(\"Counts by injury status:\")\nprint(status_counts)\n\n# Plot pie chart\nstatus_counts.plot(\n    kind='pie',\n    colors=['skyblue', 'salmon'],\n    autopct='%1.1f%%',\n    startangle=90,\n    ylabel='',\n    title='Proportion of Healthy vs Injured Samples'\n)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Configuration Setup","metadata":{}},{"cell_type":"code","source":"# Configuration Class\n# This class stores all important constants and settings in one centralized location\nclass Config:\n    SEED = 42  # Random seed for reproducibility\n    IMAGE_SIZE = (128, 128, 128)  # Dimensions for resizing 3D volumes (depth, height, width)\n    BATCH_SIZE = 16  # Number of samples per batch\n    EPOCHS = 100  # Total number of training epochs\n    LR = 3e-4  # Initial learning rate\n    \n    # Target columns (all labels to predict)\n    TARGET_COLS = [\n        \"bowel_healthy\", \"extravasation_healthy\",\n        \"bowel_injury\", \"extravasation_injury\",\n        \"kidney_healthy\", \"kidney_low\", \"kidney_high\",\n        \"liver_healthy\", \"liver_low\", \"liver_high\",\n        \"spleen_healthy\", \"spleen_low\", \"spleen_high\",\n    ]\n\n    NUM_CLASSES = len(TARGET_COLS)  # Total number of target classes\n    VOXEL_SPACING = (1.0, 1.0, 1.0)  # Used to normalize spacing in 3D CT scans\n    SPLIT_MODE = \"group\"  # 'group' for stratified grouping, 'random' for simple random split\n\n# Create an instance of the Config class to use throughout the code\nconfig = Config()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Data Transforms","metadata":{}},{"cell_type":"code","source":"# These transformations are applied to training data for augmentation and normalization\ntrain_transforms = Compose([\n    EnsureChannelFirst(),  # Ensure input has channel dimension\n    EnsureType(),  # Convert to MetaTensor\n    Orientation(axcodes=\"RAS\"),  # Standardize orientation\n    Spacing(pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),  # Normalize voxel spacing\n    Resize(spatial_size=config.IMAGE_SIZE),  # Resize to target dimensions\n\n    # Random augmentations - only one will be applied per sample (OneOf)\n    OneOf([\n        RandAffine(\n            rotate_range=(0, 0, np.pi/12),  # Limited Z-axis rotation\n            shear_range=(0.1, 0.1, 0.1),\n            translate_range=(10, 10, 5),\n            scale_range=(0.1, 0.1, 0.1),\n            prob=0.5,\n            mode=\"bilinear\"\n        ),\n        RandFlip(prob=0.5, spatial_axis=0),  # Random flip along depth\n        RandFlip(prob=0.5, spatial_axis=1),  # Random flip along height\n        RandFlip(prob=0.5, spatial_axis=2),  # Random flip along width\n    ]),\n    \n    # Intensity normalization and augmentation\n    NormalizeIntensity(nonzero=True, channel_wise=True),\n    RandScaleIntensity(factors=0.1, prob=1.0),\n    RandShiftIntensity(offsets=0.1, prob=1.0),\n    RandGaussianNoise(prob=0.3, mean=0.0, std=0.1),\n    RandAdjustContrast(prob=0.3, gamma=(0.7, 1.5)),\n\n    # Additional safe augmentations\n    RandGaussianSmooth(\n        prob=0.2,\n        sigma_x=(0.25, 0.5),  # Mild smoothing\n        sigma_y=(0.25, 0.5),\n        sigma_z=(0.25, 0.5)\n    ),\n    RandBiasField(\n        prob=0.2,\n        coeff_range=(0.1, 0.3)  # Subtle intensity variations\n    ),\n\n    ToTensor()  # Convert to PyTorch tensor\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.840936Z","iopub.status.idle":"2025-08-04T10:22:53.841237Z","shell.execute_reply.started":"2025-08-04T10:22:53.841117Z","shell.execute_reply":"2025-08-04T10:22:53.841130Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Validation Transforms","metadata":{}},{"cell_type":"code","source":"# Only basic preprocessing - no random augmentations\nval_transforms = Compose([\n    EnsureChannelFirst(),  # Add channel dimension\n    EnsureType(),  # Convert to MetaTensor\n    Orientation(axcodes=\"RAS\"),  # Standard orientation\n    Spacing(pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),  # Uniform voxel spacing\n    Resize(spatial_size=config.IMAGE_SIZE),  # Resize to target dimensions\n    NormalizeIntensity(nonzero=True, channel_wise=True),  # Normalize intensities\n    ToTensor()  # Convert to tensor\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.842198Z","iopub.status.idle":"2025-08-04T10:22:53.842477Z","shell.execute_reply.started":"2025-08-04T10:22:53.842326Z","shell.execute_reply":"2025-08-04T10:22:53.842342Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test Transforms","metadata":{}},{"cell_type":"code","source":"# Same as validation transforms - no randomness for consistent evaluation\ntest_transforms = Compose([\n    EnsureChannelFirst(),\n    EnsureType(),\n    Orientation(axcodes=\"RAS\"),\n    Spacing(pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n    Resize(spatial_size=config.IMAGE_SIZE),\n    NormalizeIntensity(nonzero=True, channel_wise=True),\n    ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.843510Z","iopub.status.idle":"2025-08-04T10:22:53.843820Z","shell.execute_reply.started":"2025-08-04T10:22:53.843630Z","shell.execute_reply":"2025-08-04T10:22:53.843644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Preparation","metadata":{}},{"cell_type":"markdown","source":"### Label Conversion and Target Formatting","metadata":{}},{"cell_type":"code","source":"def convert_labels_to_targets(label_dict):\n    \"\"\"\n    Convert the multi-label dictionary into a simplified target format.\n    For binary targets (bowel, extravasation): 0=healthy, 1=injury\n    For multi-class targets (kidney, liver, spleen): 0=healthy, 1=low, 2=high\n    \"\"\"\n    # Binary targets\n    bowel = label_dict['bowel_injury']\n    extra = label_dict['extravasation_injury']\n\n    # Multi-class targets\n    def get_class(keys):\n        for i, key in enumerate(keys):\n            if label_dict[key] == 1:\n                return i\n        return 0  # Default to healthy if no injury found\n\n    kidney = get_class(['kidney_healthy', 'kidney_low', 'kidney_high'])\n    liver = get_class(['liver_healthy', 'liver_low', 'liver_high'])\n    spleen = get_class(['spleen_healthy', 'spleen_low', 'spleen_high'])\n\n    return {\n        \"bowel\": float(bowel),\n        \"extra\": float(extra),\n        \"kidney\": kidney,\n        \"liver\": liver,\n        \"spleen\": spleen,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.845288Z","iopub.status.idle":"2025-08-04T10:22:53.845567Z","shell.execute_reply.started":"2025-08-04T10:22:53.845407Z","shell.execute_reply":"2025-08-04T10:22:53.845417Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Custom Dataset Class Implementation","metadata":{}},{"cell_type":"code","source":"class RSNADataset(Dataset):\n    \"\"\"\n    Custom dataset class for loading and processing 3D CT scans and their labels.\n    \"\"\"\n    def __init__(self, metadata_list, transforms=None, has_labels=True):\n        \"\"\"\n        Args:\n            metadata_list: List of dictionaries with 'nifti_path' and 'labels'\n            transforms: MONAI transforms to apply\n            has_labels: Whether to return labels (True for train/val, False for test)\n        \"\"\"\n        self.metadata_list = metadata_list\n        self.transforms = transforms\n        self.has_labels = has_labels\n\n    def __len__(self):\n        return len(self.metadata_list)\n\n    def __getitem__(self, idx):\n        entry = self.metadata_list[idx]\n\n        # Load NIfTI file\n        nifti_path = entry[\"nifti_path\"]\n        nifti_img = nib.load(nifti_path)\n        volume = nifti_img.get_fdata().astype(np.float32)\n\n        # Rearrange dimensions from (X, Y, Z) to (Z, Y, X)\n        volume = np.transpose(volume, (2, 1, 0))\n\n        # Add channel dimension: (1, Z, Y, X)\n        volume = np.expand_dims(volume, axis=0)\n\n        # Wrap in MetaTensor for MONAI compatibility\n        meta = {\"original_channel_dim\": 0}\n        sample = MetaTensor(volume, meta=meta)\n\n        # Apply transforms if provided\n        if self.transforms:\n            sample = self.transforms(sample)\n\n        # Package label if available\n        if self.has_labels:\n            targets = convert_labels_to_targets(entry['labels'])\n            label_array = np.array([\n                targets[\"bowel\"],\n                targets[\"extra\"],\n                targets[\"kidney\"],\n                targets[\"liver\"],\n                targets[\"spleen\"],\n            ], dtype=np.float32)\n            \n            sample = {\n                \"image\": sample,\n                \"label\": label_array,\n            }\n        else:\n            sample = {\"image\": sample}\n\n        return sample","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Balanced DataLoader Creation","metadata":{}},{"cell_type":"code","source":"def prepare_balanced_dataloaders(metadata_list, train_transforms, val_transforms, test_transforms, config):\n    \"\"\"\n    Create balanced dataloaders by oversampling minority classes.\n    Returns train, validation, and test datasets and dataloaders.\n    \"\"\"\n    def filter_by_condition(label_key, value=1):\n        return [m for m in metadata_list if m[\"labels\"].get(label_key, 0) == value]\n\n    def filter_multi_organ_injury(min_injuries=2):\n        return [m for m in metadata_list if sum([m[\"labels\"].get(k, 0) for k in config.TARGET_COLS]) >= min_injuries]\n\n    # Use a dict to avoid duplicates (keyed by nifti_path)\n    balanced_dict = {}\n\n    def add_to_balanced(samples):\n        for sample in samples:\n            balanced_dict[sample[\"nifti_path\"]] = sample\n\n    # Balance bowel (binary)\n    bowel_injury = filter_by_condition(\"bowel_injury\")\n    bowel_healthy = np.random.choice(filter_by_condition(\"bowel_healthy\"), size=len(bowel_injury), replace=False)\n    add_to_balanced(bowel_injury)\n    add_to_balanced(bowel_healthy)\n\n    # Balance extravasation (binary)\n    extrav_injury = filter_by_condition(\"extravasation_injury\")\n    extrav_healthy = np.random.choice(filter_by_condition(\"extravasation_healthy\"), size=len(extrav_injury), replace=False)\n    add_to_balanced(extrav_injury)\n    add_to_balanced(extrav_healthy)\n\n    # Balance kidney (3-class)\n    kidney_low = filter_by_condition(\"kidney_low\")\n    kidney_high = filter_by_condition(\"kidney_high\")\n    kidney_healthy = np.random.choice(filter_by_condition(\"kidney_healthy\"), size=len(kidney_low) + len(kidney_high), replace=False)\n    add_to_balanced(kidney_low)\n    add_to_balanced(kidney_high)\n    add_to_balanced(kidney_healthy)\n\n    # Balance liver (3-class)\n    liver_low = filter_by_condition(\"liver_low\")\n    liver_high = filter_by_condition(\"liver_high\")\n    liver_healthy = np.random.choice(filter_by_condition(\"liver_healthy\"), size=len(liver_low) + len(liver_high), replace=False)\n    add_to_balanced(liver_low)\n    add_to_balanced(liver_high)\n    add_to_balanced(liver_healthy)\n\n    # Balance spleen (3-class)\n    spleen_low = filter_by_condition(\"spleen_low\")\n    spleen_high = filter_by_condition(\"spleen_high\")\n    spleen_healthy = np.random.choice(filter_by_condition(\"spleen_healthy\"), size=len(spleen_low) + len(spleen_high), replace=False)\n    add_to_balanced(spleen_low)\n    add_to_balanced(spleen_high)\n    add_to_balanced(spleen_healthy)\n\n    # Add multi-organ injury samples\n    multi_organ_samples = filter_multi_organ_injury(min_injuries=2)\n    np.random.shuffle(multi_organ_samples)\n    multi_sample_limit = min(100, len(multi_organ_samples))  # Limit to 100 or available\n    add_to_balanced(multi_organ_samples[:multi_sample_limit])\n\n    # Convert to unique list\n    balanced_metadata = list(balanced_dict.values())\n\n    # Split the data\n    if config.SPLIT_MODE == \"random\":\n        def simplified_strat_key(m):\n            # Total number of positive labels across all target columns\n            return sum([m[\"labels\"].get(k, 0) for k in config.TARGET_COLS])\n\n        strat_labels = [simplified_strat_key(m) for m in balanced_metadata]\n\n        train_meta, temp_meta = train_test_split(\n            balanced_metadata,\n            test_size=0.3,\n            random_state=42,\n            stratify=strat_labels\n        )\n\n        val_labels = [simplified_strat_key(m) for m in temp_meta]\n        val_meta, test_meta = train_test_split(\n            temp_meta,\n            test_size=0.5,\n            random_state=42,\n            stratify=val_labels\n        )\n\n    elif config.SPLIT_MODE == \"group\":\n        train_meta, val_meta, test_meta = split_metadata_train_val_test(\n            balanced_metadata,\n            target_cols=config.TARGET_COLS,\n            val_size=0.15,\n            test_size=0.15,\n            seed=42\n        )\n\n    # Create Dataset and DataLoaders\n    train_ds = RSNADataset(train_meta, transforms=train_transforms)\n    val_ds = RSNADataset(val_meta, transforms=val_transforms)\n    test_ds = RSNADataset(test_meta, transforms=test_transforms)\n\n    return (\n        train_ds,\n        val_ds,\n        test_ds,\n        DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True),\n        DataLoader(val_ds, batch_size=config.BATCH_SIZE, shuffle=False),\n        DataLoader(test_ds, batch_size=1, shuffle=False),\n        train_meta\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Stratified Data Splitting","metadata":{}},{"cell_type":"code","source":"def split_metadata_train_val_test(metadata_list, target_cols, val_size=0.1, test_size=0.1, seed=42):\n    \"\"\"\n    Custom stratified split to maintain label distribution across train, validation, and test sets.\n    \"\"\"\n    # Convert metadata into DataFrame\n    df = pd.DataFrame(metadata_list)\n\n    # Extract individual labels into separate columns\n    label_df = pd.json_normalize(df['labels'])\n    df = pd.concat([df.drop(columns='labels'), label_df], axis=1)\n\n    # Group rows by all target label combinations\n    grouped = df.groupby(target_cols)\n\n    # Initialize empty splits\n    train_df, val_df, test_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n\n    val_test_size = val_size + test_size\n\n    for _, group in grouped:\n        n = len(group)\n        if n == 1:\n            # For single-sample groups, randomly assign to one set\n            r = np.random.rand()\n            if r < test_size:\n                test_df = pd.concat([test_df, group], ignore_index=True)\n            elif r < val_test_size:\n                val_df = pd.concat([val_df, group], ignore_index=True)\n            else:\n                train_df = pd.concat([train_df, group], ignore_index=True)\n        else:\n            # For larger groups, do proper stratified splits\n            train_split, val_test_split = train_test_split(group, test_size=val_test_size, random_state=seed)\n\n            if len(val_test_split) < 2:\n                val_split = val_test_split\n                test_split = pd.DataFrame()\n            else:\n                relative_test_size = test_size / val_test_size if val_test_size > 0 else 0\n                val_split, test_split = train_test_split(val_test_split, test_size=relative_test_size, random_state=seed)\n\n            train_df = pd.concat([train_df, train_split], ignore_index=True)\n            val_df = pd.concat([val_df, val_split], ignore_index=True)\n            test_df = pd.concat([test_df, test_split], ignore_index=True)\n\n    # Convert DataFrame rows back to metadata format\n    def row_to_metadata(row):\n        return {\n            \"nifti_path\": row[\"nifti_path\"],\n            \"labels\": {col: row[col] for col in target_cols}\n        }\n\n    train_list = [row_to_metadata(row) for _, row in train_df.iterrows()]\n    val_list = [row_to_metadata(row) for _, row in val_df.iterrows()]\n    test_list = [row_to_metadata(row) for _, row in test_df.iterrows()]\n\n    return train_list, val_list, test_list\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare Data Using the Loader Function (with subset for tuning)\ntrain_ds, val_ds, test_ds, train_loader, val_loader, test_loader, train_meta = prepare_balanced_dataloaders(\n    metadata_list=metadata_list,\n    train_transforms=train_transforms,\n    val_transforms=val_transforms,\n    test_transforms=test_transforms,\n    config=config\n)\n\nprint(f\"Train size: {len(train_loader.dataset)}\")\nprint(f\"Val size:   {len(val_loader.dataset)}\")\nprint(f\"Test size:  {len(test_loader.dataset)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Class Balancing and Weighted Sampling","metadata":{}},{"cell_type":"code","source":"def compute_sample_weights(metadata_list, target_cols, power=1.0):\n    \"\"\"\n    Compute sample weights based on inverse class frequency to address class imbalance.\n    \n    Args:\n        metadata_list: List of dictionaries containing label information\n        target_cols: List of target columns to consider for weight calculation\n        power: Exponent for weighting (higher values increase emphasis on rare classes)\n    \n    Returns:\n        List of sample weights for each entry in metadata_list\n    \"\"\"\n    # Extract label values for each sample\n    label_rows = []\n    for entry in metadata_list:\n        row = [entry[\"labels\"].get(col, 0) for col in target_cols]\n        label_rows.append(row)\n    \n    # Convert to numpy array for vectorized operations\n    labels_np = np.array(label_rows)\n    \n    # Calculate class frequencies with small epsilon to avoid division by zero\n    class_freq = labels_np.mean(axis=0) + 1e-6\n    \n    # Compute class weights using inverse frequency weighting\n    class_weights = 1.0 / (class_freq ** power)\n    \n    # Calculate final sample weights by combining class weights\n    sample_weights = (labels_np * class_weights).sum(axis=1)\n    return sample_weights.tolist()\n\n# Compute sample weights with power=2.0 to strongly emphasize rare classes\nsample_weights = compute_sample_weights(train_meta, config.TARGET_COLS, power=2.0)\n\n# Create weighted sampler for training data\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),  # Maintain same dataset size\n    replacement=True  # Allow sampling with replacement\n)\n\n# Create training DataLoader with weighted sampling\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=config.BATCH_SIZE,\n    sampler=sampler,  # Use our weighted sampler\n    num_workers=4  # Parallel data loading\n)\n\n# Verify class distribution after sampling\nsample_indices = list(sampler)\nsampled_labels = [train_meta[i][\"labels\"] for i in sample_indices]\n\n# Count occurrences of each label in the sampled data\ncounts = Counter()\nfor lbl in sampled_labels:\n    for k, v in lbl.items():\n        if v == 1:\n            counts[k] += 1\n\nprint(\"Class distribution after weighted sampling:\")\nprint(dict(counts))\n\n# Analyze training set label distribution\nconverted_labels = [convert_labels_to_targets(entry['labels']) for entry in train_ds.metadata_list]\n\n# Count occurrences for each organ/condition\nbowel_dist = Counter([x['bowel'] for x in converted_labels])\nextra_dist = Counter([x['extra'] for x in converted_labels])\nkidney_dist = Counter([x['kidney'] for x in converted_labels])\nliver_dist = Counter([x['liver'] for x in converted_labels])\nspleen_dist = Counter([x['spleen'] for x in converted_labels])\n\nprint(\"\\nTraining Set Label Distribution:\")\nprint(\"Bowel:\", dict(bowel_dist))\nprint(\"Extravasation:\", dict(extra_dist))\nprint(\"Kidney:\", dict(kidney_dist))\nprint(\"Liver:\", dict(liver_dist))\nprint(\"Spleen:\", dict(spleen_dist))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.852219Z","iopub.status.idle":"2025-08-04T10:22:53.852560Z","shell.execute_reply.started":"2025-08-04T10:22:53.852380Z","shell.execute_reply":"2025-08-04T10:22:53.852404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Architecture Implementation","metadata":{}},{"cell_type":"code","source":"class DenseNet121model(nn.Module):\n    \"\"\"Custom 3D DenseNet121 model with multiple classification heads.\n    \n    Features:\n    - MONAI's 3D DenseNet121 backbone with Global Average Pooling\n    - Separate heads for each prediction task (binary and multi-class)\n    - Integrated Grad-CAM functionality for visualization\n    \"\"\"\n    \n    def __init__(self, in_channels=1, pretrained=False):\n        \"\"\"Initialize the model architecture.\n        \n        Args:\n            in_channels: Number of input channels (1 for grayscale CT scans)\n            pretrained: Whether to use pretrained weights for the backbone\n        \"\"\"\n        super().__init__()\n        \n        # Variables for Grad-CAM visualization\n        self.activations = None  # Stores layer activations\n        self.gradients = None   # Stores gradients for visualization\n        \n        # Initialize DenseNet121 backbone with Global Average Pooling\n        self.backbone = DenseNet121(\n            spatial_dims=3,       # 3D version for volumetric data\n            in_channels=in_channels,\n            out_channels=512,     # Feature dimension after GAP\n            pretrained=pretrained\n        )\n        \n        # Register hook to capture activations from last convolutional layer\n        self.backbone.features[-1].register_forward_hook(self.save_activation)\n        \n        # Initialize task-specific classification heads\n        self.bowel_head = self._create_binary_head()    # Binary classification\n        self.extra_head = self._create_binary_head()    # Binary classification  \n        self.liver_head = self._create_multiclass_head()  # 3-class classification\n        self.kidney_head = self._create_multiclass_head() # 3-class classification\n        self.spleen_head = self._create_multiclass_head() # 3-class classification\n        \n    def _create_binary_head(self):\n        \"\"\"Create a binary classification head (1 output neuron with sigmoid).\"\"\"\n        return nn.Sequential(\n            nn.Linear(512, 256),    # FC layer\n            nn.BatchNorm1d(256),    # Batch normalization\n            nn.SiLU(),             # Swish activation\n            nn.Dropout(0.3),        # Regularization\n            nn.Linear(256, 1)       # Final output\n        )\n    \n    def _create_multiclass_head(self):\n        \"\"\"Create a multi-class classification head (3 output neurons with softmax).\"\"\"\n        return nn.Sequential(\n            nn.Linear(512, 256),    # FC layer\n            nn.BatchNorm1d(256),    # Batch normalization  \n            nn.SiLU(),              # Swish activation\n            nn.Dropout(0.3),        # Regularization\n            nn.Linear(256, 3)       # Final output (3 classes)\n        )\n    \n    def save_activation(self, module, input, output):\n        \"\"\"Hook function to save activations for Grad-CAM visualization.\"\"\"\n        self.activations = output\n        if output.requires_grad:\n            output.register_hook(self.save_gradient)\n    \n    def save_gradient(self, grad):\n        \"\"\"Hook function to save gradients for Grad-CAM visualization.\"\"\"\n        self.gradients = grad\n    \n    def forward(self, x):\n        \"\"\"Forward pass through the network.\n        \n        Args:\n            x: Input tensor (batch of 3D CT scans)\n            \n        Returns:\n            Dictionary containing predictions for all targets\n        \"\"\"\n        # Prepare for Grad-CAM if in training mode\n        if x.requires_grad:\n            x.register_hook(self.save_gradient)\n        self.activations = x\n        \n        # Extract features using backbone (output shape: [batch_size, 512])\n        features = self.backbone(x)\n        \n        # Return predictions for all target organs\n        return {\n            \"bowel\": self.bowel_head(features),\n            \"extra\": self.extra_head(features),\n            \"liver\": self.liver_head(features),\n            \"kidney\": self.kidney_head(features),\n            \"spleen\": self.spleen_head(features)\n        }\n    \n    def get_activations_gradient(self):\n        \"\"\"Get gradients for visualization purposes.\"\"\"\n        return self.gradients\n    \n    def get_activations(self):\n        \"\"\"Get activations for visualization purposes.\"\"\"\n        return self.activations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.857661Z","iopub.status.idle":"2025-08-04T10:22:53.858024Z","shell.execute_reply.started":"2025-08-04T10:22:53.857838Z","shell.execute_reply":"2025-08-04T10:22:53.857853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize model and move to appropriate device (GPU if available)\nmodel = DenseNet121model().to(device)\nprint(f\"Model initialized and moved to device: {next(model.parameters()).device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Loss Functions Implementation","metadata":{}},{"cell_type":"code","source":"class BinaryFocalLoss(nn.Module):\n    \"\"\"Focal loss for binary classification tasks.\n    \n    Addresses class imbalance by down-weighting well-classified examples.\n    Combines BCEWithLogitsLoss with focal loss adjustment.\n    \"\"\"\n    def __init__(self, pos_weight=None, gamma=2.0, reduction='mean'):\n        \"\"\"\n        Args:\n            pos_weight: Weight for positive class (for class balancing)\n            gamma: Focusing parameter (higher values down-weight easy examples more)\n            reduction: 'mean', 'sum' or None for loss reduction\n        \"\"\"\n        super().__init__()\n        self.pos_weight = pos_weight  # Weight for positive class\n        self.gamma = gamma           # Focusing parameter\n        self.reduction = reduction   # Loss reduction method\n\n    def forward(self, inputs, targets):\n        \"\"\"Compute focal loss for binary classification.\n        \n        Args:\n            inputs: Raw model outputs (logits, not sigmoided)\n            targets: Ground truth labels (0 or 1)\n        \"\"\"\n        # Compute standard binary cross entropy loss\n        bce_loss = F.binary_cross_entropy_with_logits(\n            inputs, targets, \n            pos_weight=self.pos_weight, \n            reduction='none'\n        )\n        \n        # Compute probabilities from logits\n        probs = torch.sigmoid(inputs)\n        \n        # Calculate modulating factor (1 - p_t)^gamma\n        p_t = probs * targets + (1 - probs) * (1 - targets)\n        focal_factor = (1 - p_t) ** self.gamma\n        \n        # Apply focal factor to BCE loss\n        loss = focal_factor * bce_loss\n\n        # Apply reduction if specified\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.861574Z","iopub.status.idle":"2025-08-04T10:22:53.861897Z","shell.execute_reply.started":"2025-08-04T10:22:53.861721Z","shell.execute_reply":"2025-08-04T10:22:53.861734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiClassFocalLoss(nn.Module):\n    \"\"\"Focal loss for multi-class classification tasks.\n    \n    Addresses class imbalance by down-weighting well-classified examples.\n    Combines CrossEntropyLoss with focal loss adjustment.\n    \"\"\"\n    def __init__(self, weight=None, gamma=2.0, reduction='mean'):\n        \"\"\"\n        Args:\n            weight: Class weights tensor (for class balancing)\n            gamma: Focusing parameter\n            reduction: 'mean', 'sum' or None for loss reduction\n        \"\"\"\n        super().__init__()\n        self.weight = weight    # Class weights\n        self.gamma = gamma      # Focusing parameter\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        \"\"\"Compute focal loss for multi-class classification.\n        \n        Args:\n            inputs: Raw model outputs (logits, not softmaxed)\n            targets: Ground truth class indices\n        \"\"\"\n        # Compute standard cross entropy loss\n        ce_loss = F.cross_entropy(\n            inputs, targets, \n            weight=self.weight, \n            reduction='none'\n        )\n        \n        # Compute probabilities from logits\n        probs = F.softmax(inputs, dim=1)\n        \n        # Gather probabilities of true classes\n        targets_unsq = targets.unsqueeze(1)\n        p_t = probs.gather(1, targets_unsq).squeeze(1)\n        \n        # Calculate modulating factor (1 - p_t)^gamma\n        focal_factor = (1 - p_t) ** self.gamma\n        \n        # Apply focal factor to CE loss\n        loss = focal_factor * ce_loss\n\n        # Apply reduction if specified\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.863664Z","iopub.status.idle":"2025-08-04T10:22:53.863946Z","shell.execute_reply.started":"2025-08-04T10:22:53.863837Z","shell.execute_reply":"2025-08-04T10:22:53.863850Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Label Smoothing Focal Loss Implementation","metadata":{}},{"cell_type":"code","source":"class LabelSmoothingFocalLoss(nn.Module):\n    \"\"\"Combines label smoothing with focal loss for multi-class classification.\n    \n    Particularly effective for highly imbalanced datasets.\n    \"\"\"\n    def __init__(self, gamma=2.0, smoothing=0.1, weight=None, reduction='mean'):\n        \"\"\"\n        Args:\n            gamma: Focusing parameter\n            smoothing: Label smoothing factor (0-1)\n            weight: Class weights tensor\n            reduction: 'mean', 'sum' or None for loss reduction\n        \"\"\"\n        super(LabelSmoothingFocalLoss, self).__init__()\n        self.gamma = gamma          # Focusing parameter\n        self.smoothing = smoothing  # Label smoothing factor\n        self.weight = weight        # Class weights\n        self.reduction = reduction  # Loss reduction method\n\n    def forward(self, inputs, targets):\n        \"\"\"Compute label smoothed focal loss.\n        \n        Args:\n            inputs: Raw model outputs (logits)\n            targets: Ground truth class indices\n        \"\"\"\n        num_classes = inputs.size(1)\n        \n        # Create smoothed label distribution\n        with torch.no_grad():\n            true_dist = torch.zeros_like(inputs)\n            true_dist.fill_(self.smoothing / (num_classes - 1))\n            true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - self.smoothing)\n\n        # Compute log probabilities\n        log_probs = F.log_softmax(inputs, dim=1)\n        probs = torch.exp(log_probs)\n        \n        # Calculate focal factor\n        focal_factor = (1 - probs).pow(self.gamma)\n\n        # Apply class weights if provided\n        if self.weight is not None:\n            weight = self.weight.unsqueeze(0)  # shape (1, C)\n            log_probs = log_probs * weight\n\n        # Compute final loss\n        loss = -true_dist * focal_factor * log_probs\n        loss = loss.sum(dim=1)\n\n        # Apply reduction\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Class Weight Calculation","metadata":{}},{"cell_type":"code","source":"# Class counts from oversampled training data\noversampled_counts = {\n    'extravasation_healthy': 1396,\n    'extravasation_injury': 447,\n    'bowel_healthy': 1526,\n    'bowel_injury': 317,\n    'kidney_healthy': 1173,\n    'kidney_low': 334,\n    'kidney_high': 336,\n    'liver_healthy': 1167,\n    'liver_low': 349,\n    'liver_high': 327,\n    'spleen_healthy': 1180,\n    'spleen_low': 331,\n    'spleen_high': 332\n}\n\ndef compute_class_weights_from_counts(counts_dict, device='cpu', pos_weight_cap=10.0, balance_threshold=1.5):\n    \"\"\"Calculate class weights from count statistics.\n    \n    Args:\n        counts_dict: Dictionary of class counts\n        device: Target device for weight tensors\n        pos_weight_cap: Maximum value for positive class weights\n        balance_threshold: Ratio threshold to consider classes balanced\n        \n    Returns:\n        bce_weights: Dictionary of weights for binary classification tasks\n        ce_weights: Dictionary of weights for multi-class classification tasks\n    \"\"\"\n    bce_weights = {}\n\n    # Binary classes (bowel, extravasation)\n    for key in [\"bowel\", \"extravasation\"]:\n        pos = counts_dict[f\"{key}_injury\"]\n        neg = counts_dict[f\"{key}_healthy\"]\n\n        # Avoid division by zero\n        pos = max(pos, 1e-6)\n        neg = max(neg, 1e-6)\n        ratio = neg / pos\n\n        # Apply weighting only if significantly imbalanced\n        if 1 / balance_threshold <= ratio <= balance_threshold:\n            pos_weight = 1.0\n        else:\n            pos_weight = min(ratio, pos_weight_cap)\n\n        bce_weights[key if key != \"extravasation\" else \"extra\"] = torch.tensor(\n            pos_weight, dtype=torch.float32, device=device)\n\n    # Multi-class weights (kidney, liver, spleen)\n    ce_weights = {}\n    for organ in [\"kidney\", \"liver\", \"spleen\"]:\n        healthy = counts_dict.get(f\"{organ}_healthy\", 0)\n        low = counts_dict.get(f\"{organ}_low\", 0)\n        high = counts_dict.get(f\"{organ}_high\", 0)\n\n        # Calculate inverse frequency weights\n        counts = torch.tensor([healthy, low, high], dtype=torch.float32, device=device)\n        counts = torch.clamp(counts, min=1e-6)\n        inv_freq = 1.0 / counts\n        weights = inv_freq / inv_freq.sum()\n        ce_weights[organ] = weights\n\n    return bce_weights, ce_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.864808Z","iopub.status.idle":"2025-08-04T10:22:53.865061Z","shell.execute_reply.started":"2025-08-04T10:22:53.864935Z","shell.execute_reply":"2025-08-04T10:22:53.864947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss Function and Optimizer Setup","metadata":{}},{"cell_type":"code","source":"# Calculate class weights from oversampled counts\nbce_weights, ce_weights = compute_class_weights_from_counts(\n    oversampled_counts, \n    device=device\n)\n\n# Initialize loss functions for each prediction head\nloss_fn_dict = {\n    \"bowel\": nn.BCEWithLogitsLoss(pos_weight=bce_weights[\"bowel\"]),\n    \"extra\": nn.BCEWithLogitsLoss(pos_weight=bce_weights[\"extra\"]),\n    \"kidney\": LabelSmoothingFocalLoss(\n        weight=ce_weights[\"kidney\"], \n        gamma=1.5, \n        smoothing=0.07\n    ),\n    \"liver\": LabelSmoothingFocalLoss(\n        weight=ce_weights[\"liver\"], \n        gamma=1.5, \n        smoothing=0.07\n    ),\n    \"spleen\": LabelSmoothingFocalLoss(\n        weight=ce_weights[\"spleen\"], \n        gamma=1.5, \n        smoothing=0.07\n    ),\n}\n\n# Initialize optimizer with weight decay\noptimizer = torch.optim.AdamW(\n    model.parameters(), \n    lr=1e-4, \n    weight_decay=5e-6  # L2 regularization\n)\n\n# Learning rate scheduler with warm restarts\nscheduler = CosineAnnealingWarmRestarts(\n    optimizer,\n    T_0=15,       # Number of epochs before first restart\n    T_mult=2,     # Period multiplier after each restart\n    eta_min=1e-6  # Minimum learning rate\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.867618Z","iopub.status.idle":"2025-08-04T10:22:53.867910Z","shell.execute_reply.started":"2025-08-04T10:22:53.867737Z","shell.execute_reply":"2025-08-04T10:22:53.867770Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Utilities and Configuration","metadata":{}},{"cell_type":"code","source":"def compute_head_weights_from_losses(avg_losses, head_priority=None, normalize=True, min_clip=1e-6):\n    \"\"\"\n    Compute task weights based on per-head losses to balance multi-task learning.\n    \n    Args:\n        avg_losses: Dictionary of average losses per task/head\n        head_priority: Optional priority weights for specific heads\n        normalize: Whether to normalize weights to mean 1.0\n        min_clip: Minimum value to avoid division by zero\n        \n    Returns:\n        Dictionary of weights for each task/head\n    \"\"\"\n    head_priority = head_priority or {}\n    # Compute inverse losses weighted by priority\n    inv_losses = {\n        k: (1.0 / max(v, min_clip)) * head_priority.get(k, 1.0)\n        for k, v in avg_losses.items()\n    }\n    \n    if normalize:\n        mean_inv = sum(inv_losses.values()) / len(inv_losses)\n        print('Using normalized task weights')\n        return {k: v / mean_inv for k, v in inv_losses.items()}\n    print('Using priority-weighted task weights')\n    return inv_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.871301Z","iopub.status.idle":"2025-08-04T10:22:53.871523Z","shell.execute_reply.started":"2025-08-04T10:22:53.871423Z","shell.execute_reply":"2025-08-04T10:22:53.871432Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Loop Implementation","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, loss_fn_dict, scheduler=None, \n                   grad_clip=None, debug=False, task_weights=None):\n    \"\"\"\n    Train model for one epoch with optional gradient clipping and debugging.\n    \n    Args:\n        model: Model to train\n        loader: DataLoader for training data\n        optimizer: Optimization algorithm\n        loss_fn_dict: Dictionary of loss functions per task\n        scheduler: Optional learning rate scheduler\n        grad_clip: Maximum gradient norm for clipping\n        debug: Whether to print debug information\n        task_weights: Optional weights for each task\n        \n    Returns:\n        Average loss and per-task losses for the epoch\n    \"\"\"\n    model.train()\n    running_loss = 0.0\n    task_losses = defaultdict(float)\n    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\", leave=False)\n\n    for batch_idx, batch in pbar:\n        # Prepare batch data\n        inputs = batch[\"image\"].to(device, dtype=torch.float32)\n        labels = batch[\"label\"].to(device, dtype=torch.float32)\n\n        # Add channel dimension if needed\n        if inputs.ndim == 4:\n            inputs = inputs.unsqueeze(1)\n\n        # Forward pass\n        optimizer.zero_grad(set_to_none=True)\n        outputs = model(inputs)\n\n        # Prepare targets for each task\n        targets = {\n            \"bowel\": labels[:, 0].float(),   # Binary label\n            \"extra\": labels[:, 1].float(),   # Binary label\n            \"kidney\": labels[:, 2].long(),   # Class index: 0,1,2\n            \"liver\": labels[:, 3].long(),\n            \"spleen\": labels[:, 4].long(),\n        }\n\n        loss = torch.tensor(0.0, device=device, dtype=torch.float32)\n\n        # Compute loss for each task\n        for key in outputs:\n            pred = outputs[key]\n            target = targets[key]\n\n            try:\n                if key in [\"bowel\", \"extra\"]:\n                    # Binary classification tasks\n                    pred = pred.squeeze(-1) if pred.ndim > 1 else pred\n                    task_loss = loss_fn_dict[key](pred, target)\n                else:\n                    # Multi-class classification tasks\n                    task_loss = loss_fn_dict[key](pred, target.long())\n            except Exception as e:\n                print(f\"Error in loss for {key} @ batch {batch_idx}: {e}\")\n                print(f\"   Pred shape: {pred.shape}, Target shape: {target.shape}\")\n                continue\n\n            if torch.isnan(task_loss).any():\n                print(f\"NaN in {key} loss @ batch {batch_idx}\")\n                continue\n\n            task_losses[key] += task_loss.item()\n            loss += task_loss\n\n            # Debug output every 20 batches\n            if debug and batch_idx % 20 == 0:\n                print(f\"\\n[Debug Batch {batch_idx}]\")\n                for key in outputs:\n                    pred_logits = outputs[key].detach().cpu().numpy()\n                    target_vals = targets[key].cpu().numpy()\n            \n                    if key in [\"bowel\", \"extra\"]:\n                        print(f\"[{key}]\")\n                        print(f\"   Pred logits: {np.round(pred_logits[:3].squeeze(), 4)}\")\n                        print(f\"   Target:      {np.round(target_vals[:3], 4)}\")\n                    else:\n                        print(f\"[{key}]\")\n                        print(f\"   Pred logits:\\n{np.round(pred_logits[:3], 4)}\")\n                        print(f\"   Target:      {target_vals[:3]}\")\n\n        # Skip batch if NaN loss\n        if torch.isnan(loss).any():\n            print(f\"Skipping NaN total loss @ batch {batch_idx}\")\n            continue\n\n        # Backward pass and optimization\n        loss.backward()\n        if grad_clip:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        optimizer.step()\n\n        # Update running loss\n        running_loss += loss.item()\n        avg_loss = running_loss / (batch_idx + 1)\n        pbar.set_postfix({\"loss\": avg_loss})\n\n    # Calculate average task losses\n    task_losses = {k: v / len(loader) for k, v in task_losses.items()}\n    \n    # Print training statistics\n    print(\"Organ-wise Training Losses:\")\n    for organ, organ_loss in task_losses.items():\n        print(f\"   {organ}: {organ_loss:.4f}\")\n\n    print(f'Train loss: {avg_loss}')\n    \n    # Print current learning rate\n    for param_group in optimizer.param_groups:\n        print(f\"Current LR: {param_group['lr']:.6f}\")\n    \n    return avg_loss, task_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.872564Z","iopub.status.idle":"2025-08-04T10:22:53.872874Z","shell.execute_reply.started":"2025-08-04T10:22:53.872688Z","shell.execute_reply":"2025-08-04T10:22:53.872704Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Validation and Evaluation","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef validate(model, loader, loss_fn_dict, debug=False, thresholds=None, tta_fns=None):\n    \"\"\"\n    Validate model performance on validation set.\n    \n    Args:\n        model: Model to evaluate\n        loader: DataLoader for validation data\n        loss_fn_dict: Dictionary of loss functions per task\n        debug: Whether to print debug information\n        thresholds: Decision thresholds for each task\n        tta_fns: List of test-time augmentation functions\n        \n    Returns:\n        Validation loss, metrics, per-task losses, and detailed metrics\n    \"\"\"\n    model.eval()\n    val_loss = 0.0\n    val_task_losses = defaultdict(float)\n    pbar = tqdm(loader, desc=\"Validation\", leave=False)\n\n    # Initialize storage for predictions and targets\n    all_preds = defaultdict(list)\n    all_probs = defaultdict(list)\n    all_targets = defaultdict(list)\n\n    # Set default thresholds if not provided\n    if thresholds is None:\n        thresholds = {\n            \"bowel\": {\"thresholds\": [0.01, 0.45], \"best_f1\": [0.9823, 0.7059]},\n            \"extra\": {\"thresholds\": [0.02, 0.84], \"best_f1\": [0.9493, 0.5607]},\n            \"kidney\": {\"thresholds\": [0.06, 0.79, 0.67], \"best_f1\": [0.9503, 0.6154, 0.6667]},\n            \"liver\": {\"thresholds\": [0.13, 0.60, 0.75], \"best_f1\": [0.9054, 0.5077, 0.6400]},\n            \"spleen\": {\"thresholds\": [0.14, 0.57, 0.56], \"best_f1\": [0.8905, 0.5660, 0.4938]}\n        }\n    elif isinstance(thresholds, dict) and not isinstance(list(thresholds.values())[0], dict):\n        thresholds = {k: {\"thresholds\": [v]} for k, v in thresholds.items()}\n\n    def tta_forward_batch(model, inputs, tta_fns):\n        \"\"\"Apply test-time augmentation and average predictions.\"\"\"\n        if not tta_fns:\n            return model(inputs)\n        logits_per_tta = []\n        for fn in tta_fns:\n            aug_inp = fn(inputs)\n            logits_per_tta.append(model(aug_inp))\n        # Average predictions across augmentations\n        avg_logits = {}\n        for k in logits_per_tta[0].keys():\n            avg_logits[k] = torch.stack([d[k] for d in logits_per_tta], dim=0).mean(dim=0)\n        return avg_logits\n\n    for batch_idx, batch in enumerate(pbar):\n        # Prepare batch data\n        inputs = batch[\"image\"].to(device, dtype=torch.float32)\n        labels = batch[\"label\"].to(device, dtype=torch.float32)\n\n        if inputs.ndim == 4:\n            inputs = inputs.unsqueeze(1)\n\n        # Forward pass with optional TTA\n        outputs = tta_forward_batch(model, inputs, tta_fns)\n\n        # Prepare targets for each task\n        targets = {\n            \"bowel\": labels[:, 0].float(),\n            \"extra\": labels[:, 1].float(),\n            \"kidney\": labels[:, 2].long(),\n            \"liver\": labels[:, 3].long(),\n            \"spleen\": labels[:, 4].long(),\n        }\n\n        batch_loss = 0.0\n        \n        # Process each task separately\n        for key in outputs:\n            pred = outputs[key]\n            target = targets[key]\n\n            # Binary classification tasks\n            if key in [\"bowel\", \"extra\"]:\n                probs = torch.sigmoid(pred).squeeze(-1).cpu().numpy()\n                probs = np.stack([1 - probs, probs], axis=1)  # shape (batch, 2)\n                all_probs[key].extend(probs[:, 1])  # Store positive class probabilities\n                \n                # Apply class-specific thresholds\n                class_preds = np.zeros_like(probs[:, 0], dtype=int)\n                for class_idx in [0, 1]:\n                    class_mask = (probs[:, class_idx] >= thresholds[key][\"thresholds\"][class_idx])\n                    class_preds[class_mask] = class_idx\n                \n                target_np = target.cpu().numpy().astype(int)\n                all_preds[key].extend(class_preds)\n                all_targets[key].extend(target_np)\n                \n                loss = loss_fn_dict[key](pred.view(-1), target.float().view(-1))\n\n            # Multi-class classification tasks\n            else:\n                probs = F.softmax(pred, dim=1).cpu().numpy()\n                all_probs[key].extend(probs)\n                \n                # Apply per-class thresholds\n                final_preds = np.zeros(probs.shape[0], dtype=int)\n                for i in range(probs.shape[0]):\n                    valid_classes = [c for c in range(probs.shape[1]) \n                                  if probs[i, c] >= thresholds[key][\"thresholds\"][c]]\n                    \n                    if valid_classes:\n                        final_preds[i] = valid_classes[np.argmax(probs[i, valid_classes])]\n                    else:\n                        final_preds[i] = 0  # Default to healthy class\n                \n                target_np = target.cpu().numpy()\n                all_preds[key].extend(final_preds)\n                all_targets[key].extend(target_np)\n\n                loss = loss_fn_dict[key](pred, target)\n\n            val_task_losses[key] += loss.item()\n            batch_loss += loss.item()\n\n    val_loss += batch_loss\n    pbar.set_postfix({\"val_loss\": val_loss / (pbar.n + 1)})\n\n    # Calculate comprehensive metrics\n    metrics = {}\n    history_metrics = {}  # Simplified metrics for training history\n    \n    for organ in all_preds:\n        y_true = np.array(all_targets[organ])\n        y_pred = np.array(all_preds[organ])\n        y_probs = np.array(all_probs[organ])\n        \n        # Binary classification metrics\n        if organ in [\"bowel\", \"extra\"]:\n            precision, recall, f1, _ = precision_recall_fscore_support(\n                y_true, y_pred, average='binary', zero_division=0\n            )\n            accuracy = accuracy_score(y_true, y_pred)\n            try:\n                roc_auc = roc_auc_score(y_true, y_probs)\n            except ValueError:\n                roc_auc = 0.0\n            \n            # Confusion matrix components\n            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n            \n            metrics[organ] = {\n                'precision': precision,\n                'recall': recall,\n                'f1': f1,\n                'roc_auc': roc_auc,\n                'accuracy': accuracy,\n                'confusion_matrix': {\n                    'true_negative': tn,\n                    'false_positive': fp,\n                    'false_negative': fn,\n                    'true_positive': tp\n                }\n            }\n            \n            history_metrics[organ] = {\n                'precision': precision,\n                'recall': recall,\n                'f1': f1,\n                'roc_auc': roc_auc,\n                'accuracy': accuracy\n            }\n        \n        # Multi-class classification metrics\n        else:\n            # Per-class metrics\n            precision, recall, f1, support = precision_recall_fscore_support(\n                y_true, y_pred, average=None, zero_division=0\n            )\n            \n            # Macro averages\n            macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n                y_true, y_pred, average='macro', zero_division=0\n            )\n            \n            accuracy = accuracy_score(y_true, y_pred)\n            \n            # Multi-class ROC AUC\n            try:\n                if y_probs.ndim == 2:\n                    roc_auc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n                else:\n                    roc_auc = 0.0\n            except ValueError:\n                roc_auc = 0.0\n            \n            # Full confusion matrix\n            cm = confusion_matrix(y_true, y_pred)\n            \n            metrics[organ] = {\n                'precision': precision.tolist(),\n                'recall': recall.tolist(),\n                'f1': f1.tolist(),\n                'support': support.tolist(),\n                'macro_precision': macro_precision,\n                'macro_recall': macro_recall,\n                'macro_f1': macro_f1,\n                'accuracy': accuracy,\n                'roc_auc': roc_auc,\n                'confusion_matrix': cm.tolist()\n            }\n            \n            history_metrics[organ] = {\n                'precision': macro_precision,\n                'recall': macro_recall,\n                'f1': macro_f1,\n                'roc_auc': roc_auc,\n                'accuracy': accuracy\n            }\n\n    val_task_losses = {k: v / len(loader) for k, v in val_task_losses.items()}\n    return val_loss / len(loader), history_metrics, val_task_losses, metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.873731Z","iopub.status.idle":"2025-08-04T10:22:53.874041Z","shell.execute_reply.started":"2025-08-04T10:22:53.873892Z","shell.execute_reply":"2025-08-04T10:22:53.873901Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Checkpoint Management","metadata":{}},{"cell_type":"code","source":"# Initialize Kaggle API\napi = KaggleApi()\napi.authenticate()\n\ndef upload_to_kaggle_model(dataset_owner, dataset_slug, model_path, checkpoint_path=None, version_note=\"\"):\n    \"\"\"\n    Upload model artifacts to Kaggle datasets.\n    \n    Args:\n        dataset_owner: Owner of the target dataset\n        dataset_slug: Name of the target dataset\n        model_path: Path to model file\n        checkpoint_path: Path to checkpoint file (optional)\n        version_note: Description for dataset version\n    \"\"\"\n    import json\n\n    zip_path = \"/kaggle/working/model_upload.zip\"\n\n    # Create zip archive of model files\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        zipf.write(model_path, arcname=os.path.basename(model_path))\n        if checkpoint_path:\n            zipf.write(checkpoint_path, arcname=os.path.basename(checkpoint_path))\n\n    print(f\"Zipped model(s) to: {zip_path}\")\n\n    # Create dataset metadata\n    metadata = {\n        \"title\": f\"{dataset_slug} model\",\n        \"id\": f\"{dataset_owner}/{dataset_slug}\",\n        \"licenses\": [{\"name\": \"CC0-1.0\"}]\n    }\n    metadata_path = \"/kaggle/working/dataset-metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f, indent=2)\n\n    print(f\"Created metadata file at {metadata_path}\")\n\n    # Upload new dataset version\n    api.dataset_create_version(\n        folder=\"/kaggle/working\",\n        version_notes=version_note,\n        delete_old_versions=False,\n        convert_to_csv=False\n    )\n    print(f\"Uploaded to Kaggle Dataset: {dataset_owner}/{dataset_slug}\")\n\ndef extract_checkpoint_from_dataset(dataset_input_path=\"/kaggle/input/bestest-dataset\",\n                                  extract_path=\"/kaggle/working\"):\n    \"\"\"\n    Extract model checkpoint files from Kaggle dataset.\n    \n    Args:\n        dataset_input_path: Path to input dataset\n        extract_path: Destination path for extracted files\n        \n    Returns:\n        Path where files were extracted, or None if no files found\n    \"\"\"\n    checkpoint_src = os.path.join(dataset_input_path, \"checkpoint.pth\")\n    best_model_src = os.path.join(dataset_input_path, \"model_best.pth\")\n\n    copied = False\n\n    if os.path.exists(checkpoint_src):\n        shutil.copy(checkpoint_src, os.path.join(extract_path, \"checkpoint.pth\"))\n        print(f\"Copied checkpoint.pth to {extract_path}\")\n        copied = True\n    else:\n        print(\"checkpoint.pth not found in dataset input.\")\n\n    if os.path.exists(best_model_src):\n        shutil.copy(best_model_src, os.path.join(extract_path, \"model_best.pth\"))\n        print(f\"Copied model_best.pth to {extract_path}\")\n        copied = True\n    else:\n        print(\"model_best.pth not found in dataset input.\")\n\n    return extract_path if copied else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.875416Z","iopub.status.idle":"2025-08-04T10:22:53.875668Z","shell.execute_reply.started":"2025-08-04T10:22:53.875547Z","shell.execute_reply":"2025-08-04T10:22:53.875560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Main Training Function","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, val_loader, optimizer, scheduler, loss_fn_dict, num_epochs,\n         save_dir=\"/kaggle/working\", resume=False,\n         upload_to_kaggle=False, dataset_owner=None, dataset_slug=None, \n         hyperparam_note=\"\", grad_clip=None,\n         custom_thresholds={\"bowel\": 0.76, \"extra\": 0.78}):\n    \"\"\"\n    Main training loop with checkpointing and optional Kaggle uploads.\n    \n    Args:\n        model: Model to train\n        train_loader: DataLoader for training data\n        val_loader: DataLoader for validation data\n        optimizer: Optimization algorithm\n        scheduler: Learning rate scheduler\n        loss_fn_dict: Dictionary of loss functions per task\n        num_epochs: Total number of training epochs\n        save_dir: Directory to save checkpoints\n        resume: Whether to resume from checkpoint\n        upload_to_kaggle: Whether to upload to Kaggle\n        dataset_owner: Kaggle dataset owner\n        dataset_slug: Kaggle dataset name\n        hyperparam_note: Notes about hyperparameters\n        grad_clip: Gradient clipping value\n        custom_thresholds: Decision thresholds for evaluation\n        \n    Returns:\n        Trained model and training history\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Define test-time augmentation functions\n    def id_fn(x): return x          # Identity\n    def flip0(x): return torch.flip(x, dims=[2])  # Flip depth\n    def flip1(x): return torch.flip(x, dims=[3])  # Flip height\n    def flip2(x): return torch.flip(x, dims=[4])  # Flip width\n    def rot90_hw(x): return torch.rot90(x, k=1, dims=(3, 4))  # Rotate 90°\n        \n    best_val_loss = float('inf')\n    start_epoch = 0\n    prev_val_task_losses = None\n\n    # Paths for model checkpoints\n    checkpoint_path = os.path.join(save_dir, \"checkpoint.pth\")\n    best_model_path = os.path.join(save_dir, \"model_best.pth\")\n\n    # Initialize training history\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'metrics': {\n            organ: {\n                'precision': [], 'recall': [], 'f1': [], 'roc_auc': [], 'accuracy': [],\n                'train_loss': [], 'val_loss': []\n            }\n            for organ in ['bowel', 'extra', 'kidney', 'liver', 'spleen']\n        },\n        'task_weights': {organ: [] for organ in ['bowel', 'extra', 'kidney', 'liver', 'spleen']}\n    }\n\n    # Resume from checkpoint if requested\n    if resume:\n        extracted_path = extract_checkpoint_from_dataset()\n        if extracted_path:\n            for file in [\"checkpoint.pth\", \"model_best.pth\"]:\n                src = os.path.join(extracted_path, file)\n                dst = os.path.join(save_dir, file)\n                if os.path.exists(src):\n                    os.replace(src, dst)\n                    print(f\"Copied {file} to {dst}\")\n\n    if resume and os.path.exists(checkpoint_path):\n        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1\n        best_val_loss = checkpoint.get('best_val_loss', best_val_loss)\n        if 'scheduler_state_dict' in checkpoint:\n            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        history = checkpoint.get('history', history)\n        prev_val_task_losses = checkpoint.get('prev_val_task_losses', None)\n        print(f\"Resumed from epoch {start_epoch}\")\n\n        # Task priority weights\n        head_priority = {\n            \"bowel\": 0.9,    # More balanced\n            \"extra\": 1.25,   # Slightly less balanced\n            \"kidney\": 1.1,   # More imbalanced\n            \"liver\": 1,      # Medium imbalance\n            \"spleen\": 1.2    # Most imbalanced\n        }\n    prev_val_task_losses = None\n\n    tta_transforms_list = [id_fn, flip0, flip1, flip2]\n\n    # Main training loop\n    for epoch in range(start_epoch, num_epochs):\n        print(f\"\\nEpoch [{epoch + 1}/{num_epochs}]\")\n\n        # Compute dynamic task weights based on previous losses\n        task_weights = {k: 1.0 for k in loss_fn_dict} if prev_val_task_losses is None \\\n            else compute_head_weights_from_losses(prev_val_task_losses, head_priority)\n\n        # Train for one epoch\n        train_loss, train_task_losses = train_one_epoch(\n            model, train_loader, optimizer, loss_fn_dict,\n            grad_clip=grad_clip,\n            task_weights=task_weights\n        )\n\n        # Validate after training\n        val_loss, metrics, val_task_losses, detailed_metrics = validate(\n            model, val_loader, loss_fn_dict, debug=False,\n            thresholds=custom_thresholds, tta_fns=None\n        )\n        \n        prev_val_task_losses = val_task_losses  # Save for next epoch\n\n        print(\"Dynamic Task Weights:\")\n        for organ, weight in task_weights.items():\n            print(f\"   {organ}: {weight:.4f}\")\n\n        # Update learning rate\n        scheduler.step()\n\n        # Update history\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n\n        for organ in metrics:\n            for metric in metrics[organ]:\n                history['metrics'][organ][metric].append(metrics[organ][metric])\n            history['metrics'][organ]['train_loss'].append(train_task_losses.get(organ, None))\n            history['metrics'][organ]['val_loss'].append(val_task_losses.get(organ, None))\n\n        for organ in history['task_weights']:\n            history['task_weights'][organ].append(task_weights.get(organ, None))\n\n        # Save checkpoint\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_loss': best_val_loss,\n            'history': history,\n            'prev_val_task_losses': prev_val_task_losses,\n        }, checkpoint_path)\n\n        # Save best model if improved\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"New best model saved! Val Loss = {val_loss:.4f}\")\n\n            if upload_to_kaggle and dataset_owner and dataset_slug:\n                note = f\"{hyperparam_note} | Epoch {epoch + 1}, Val Loss: {val_loss:.4f}\"\n                upload_to_kaggle_model(dataset_owner, dataset_slug, \n                                     best_model_path, checkpoint_path, \n                                     version_note=note)\n        else:\n            print(f\"No improvement. Val Loss = {val_loss:.4f}\")\n            if upload_to_kaggle and dataset_owner and dataset_slug:\n                note = f\"{hyperparam_note} | Epoch {epoch + 1}, No improvement\"\n                upload_to_kaggle_model(dataset_owner, dataset_slug, \n                                     model_path=checkpoint_path, \n                                     version_note=note)\n\n    return model, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.876414Z","iopub.status.idle":"2025-08-04T10:22:53.876650Z","shell.execute_reply.started":"2025-08-04T10:22:53.876530Z","shell.execute_reply":"2025-08-04T10:22:53.876542Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Configuration and Execution","metadata":{}},{"cell_type":"code","source":"# Dataset information for model saving\ndataset_owner = \"anusapkota\"\ndataset_slug = \"abdominal-trauma-detection-final-model-dataset\"\ndataset_id = f\"{dataset_owner}/{dataset_slug}\"\n\n# Custom prediction thresholds\ncustom_thresholds = {\n    \"bowel\": {\"thresholds\": [0.0, 0.6]},\n    \"extra\": {\"thresholds\": [0.0, 0.6]},\n    \"kidney\": {\"thresholds\": [0.0, 0.45, 0.66]},\n    \"liver\": {\"thresholds\": [0.0, 0.45, 0.66]},\n    \"spleen\": {\"thresholds\": [0.0, 0.50, 0.66]}\n}\n\n# Main training execution\nNUM_EPOCHS = config.EPOCHS\nsave_dir = '/kaggle/working/'\n\n# Hyperparameter notes for logging\nhyperparam_note = (\n    f\"lr={config.LR}, bs={config.BATCH_SIZE}, \"\n    f\"image_size={config.IMAGE_SIZE}, \"\n    \"focal_loss: fine tuned subset = 30%\"\n)\n\n# Check GPU availability\nprint(\"Is CUDA available?\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Current device:\", torch.cuda.current_device())\n    print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n\n# Start training\nmodel, history = train(\n    model,\n    train_loader,\n    val_loader,\n    optimizer,\n    scheduler,\n    loss_fn_dict,\n    NUM_EPOCHS,\n    save_dir,\n    resume=True,\n    upload_to_kaggle=True,\n    dataset_owner=dataset_owner,\n    dataset_slug=dataset_slug,\n    hyperparam_note=hyperparam_note, \n    custom_thresholds=custom_thresholds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.879342Z","iopub.status.idle":"2025-08-04T10:22:53.879653Z","shell.execute_reply.started":"2025-08-04T10:22:53.879497Z","shell.execute_reply":"2025-08-04T10:22:53.879511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Loading","metadata":{}},{"cell_type":"code","source":"def load_model(model_path):\n    \"\"\"Load a DenseNet121 model from a checkpoint file.\n    \n    Args:\n        model_path (str): Path to the model checkpoint file\n        \n    Returns:\n        model: Loaded and evaluated model\n    \"\"\"\n    model = DenseNet121model()\n    state_dict = torch.load(model_path, map_location='cpu', weights_only=False)\n    \n    # Handle different state dict formats\n    if 'model_state_dict' in state_dict:\n        state_dict = state_dict['model_state_dict']\n    \n    # Remove batch tracking keys if present\n    state_dict = {k: v for k, v in state_dict.items() \n                 if not k.endswith('num_batches_tracked')}\n    \n    model.load_state_dict(state_dict, strict=False)\n    model.eval()\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:22:53.882060Z","iopub.status.idle":"2025-08-04T10:22:53.882366Z","shell.execute_reply.started":"2025-08-04T10:22:53.882207Z","shell.execute_reply":"2025-08-04T10:22:53.882220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = '/kaggle/working/checkpoint.pth'\nmodel = load_model(checkpoint_path)\ncheckpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\nhistory = checkpoint['history']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation Setup","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef _tta_forward_batch(model, inputs, tta_fns):\n    \"\"\"Run a batch through the model with multiple deterministic TTA transforms\n    and return the averaged logits dict.\n    \n    Args:\n        model: The model to evaluate\n        inputs: Input tensor\n        tta_fns: List of test-time augmentation functions\n        \n    Returns:\n        Dictionary of averaged logits\n    \"\"\"\n    if not tta_fns:\n        return model(inputs)\n\n    logits_per_tta = []\n    for fn in tta_fns:\n        aug_inp = fn(inputs)\n        logits_per_tta.append(model(aug_inp))\n\n    # Average per-head\n    avg_logits = {}\n    for k in logits_per_tta[0].keys():\n        avg_logits[k] = torch.stack([d[k] for d in logits_per_tta], dim=0).mean(dim=0)\n    return avg_logits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_test_evaluation(\n    model,\n    test_ds,\n    loss_fn_dict,\n    thresholds=None,\n    batch_size=32,\n    num_workers=2,\n    tta_fns=None\n):\n    \"\"\"Run evaluation on test dataset with optional TTA.\n    \n    Args:\n        model: Model to evaluate\n        test_ds: Test dataset\n        loss_fn_dict: Dictionary of loss functions per organ\n        thresholds: Classification thresholds (defaults to pre-defined values)\n        batch_size: Evaluation batch size\n        num_workers: DataLoader workers\n        tta_fns: List of TTA functions\n        \n    Returns:\n        Tuple of (test_metrics, preds_targets)\n    \"\"\"\n    model.to(device)\n    model.eval()\n    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    print(\"Running test evaluation...\")\n\n    # Set default thresholds if not provided\n    if thresholds is None:\n        thresholds = {\n            \"bowel\": {\"thresholds\": [0.01, 0.45], \"best_f1\": [0.9823, 0.7059]},\n            \"extra\": {\"thresholds\": [0.02, 0.84], \"best_f1\": [0.9493, 0.5607]},\n            \"liver\": {\"thresholds\": [0.13, 0.60, 0.75], \"best_f1\": [0.9054, 0.5077, 0.6400]},\n            \"kidney\": {\"thresholds\": [0.06, 0.79, 0.67], \"best_f1\": [0.9503, 0.6154, 0.6667]},\n            \"spleen\": {\"thresholds\": [0.14, 0.57, 0.56], \"best_f1\": [0.8905, 0.5660, 0.4938]}\n        }\n\n    all_preds = defaultdict(list)\n    all_labels = defaultdict(list)\n    total_loss = 0.0\n    total_batches = 0\n\n    organ_indices = {\n        \"bowel\": 0,\n        \"extra\": 1,\n        \"kidney\": 2,\n        \"liver\": 3,\n        \"spleen\": 4,\n    }\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n            inputs = batch[\"image\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            # TTA-aware forward pass\n            outputs = _tta_forward_batch(model, inputs, tta_fns)\n\n            # Calculate batch loss\n            batch_loss = 0.0\n            for organ, loss_fn in loss_fn_dict.items():\n                idx = organ_indices[organ]\n                pred = outputs[organ]\n                target = labels[:, idx]\n\n                if isinstance(loss_fn, nn.BCEWithLogitsLoss):\n                    target = target.unsqueeze(1).float()\n                elif isinstance(loss_fn, nn.CrossEntropyLoss) or hasattr(loss_fn, \"smoothing\"):\n                    target = target.long()\n                else:\n                    target = target.float()\n\n                batch_loss += loss_fn(pred, target)\n\n            total_loss += batch_loss.item()\n            total_batches += 1\n\n            # Process predictions\n            for organ in outputs.keys():\n                idx = organ_indices[organ]\n                pred_tensor = outputs[organ]\n                target_tensor = labels[:, idx]\n\n                if pred_tensor.shape[-1] == 1:\n                    # Binary classification case\n                    probs = torch.sigmoid(pred_tensor).squeeze(-1).cpu()\n                    probs = torch.stack([1 - probs, probs], dim=1)\n                    organ_thresholds = thresholds[organ][\"thresholds\"]\n                    \n                    preds_arr = []\n                    for sample_probs in probs:\n                        predicted_class = 0  # default to class 0\n                        for class_idx in [1, 0]:  # check class 1 first\n                            if sample_probs[class_idx] >= organ_thresholds[class_idx]:\n                                predicted_class = class_idx\n                                break\n                        preds_arr.append(predicted_class)\n                    \n                    labels_arr = target_tensor.cpu().tolist()\n                else:\n                    # Multi-class classification case\n                    probs = torch.softmax(pred_tensor, dim=1).cpu()\n                    organ_thresholds = thresholds[organ][\"thresholds\"]\n                    \n                    preds_arr = []\n                    for sample_probs in probs:\n                        valid_classes = []\n                        for class_idx in range(probs.shape[1]):\n                            if sample_probs[class_idx] >= organ_thresholds[class_idx]:\n                                valid_classes.append(class_idx)\n                        \n                        if valid_classes:\n                            valid_probs = sample_probs[torch.tensor(valid_classes)]\n                            pred_class = valid_classes[torch.argmax(valid_probs).item()]\n                        else:\n                            pred_class = 0\n                        preds_arr.append(pred_class)\n                    \n                    labels_arr = target_tensor.cpu().tolist()\n\n                all_preds[organ].extend(preds_arr)\n                all_labels[organ].extend(labels_arr)\n\n    # Calculate final metrics\n    avg_loss = total_loss / total_batches if total_batches > 0 else 0.0\n    test_metrics = {\"loss\": avg_loss}\n    preds_targets = {\n        organ: {\"preds\": all_preds[organ], \"labels\": all_labels[organ]}\n        for organ in all_preds\n    }\n\n    print(f\"\\nTest Loss: {avg_loss:.4f}\")\n    return test_metrics, preds_targets\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Utility Functions","metadata":{}},{"cell_type":"code","source":"def save_metrics_and_preds(test_metrics, preds_targets, save_dir=\"/kaggle/working\"):\n    \"\"\"Save evaluation metrics and predictions to JSON files.\n    \n    Args:\n        test_metrics: Evaluation metrics dictionary\n        preds_targets: Predictions and targets dictionary\n        save_dir: Directory to save files\n        \n    Returns:\n        Tuple of (metrics_path, preds_path)\n    \"\"\"\n    metrics_path = os.path.join(save_dir, \"test_metrics.json\")\n    preds_path = os.path.join(save_dir, \"preds_targets.json\")\n\n    with open(metrics_path, \"w\") as f:\n        json.dump(test_metrics, f, indent=2)\n\n    with open(preds_path, \"w\") as f:\n        json.dump(preds_targets, f, indent=2)\n\n    print(f\"Saved metrics to {metrics_path}\")\n    print(f\"Saved predictions and targets to {preds_path}\")\n\n    return metrics_path, preds_path\n\ndef upload_to_kaggle_model(\n    dataset_owner, \n    dataset_slug, \n    model_path, \n    checkpoint_path=None, \n    metrics_path=None, \n    preds_path=None, \n    version_note=\"\"\n):\n    \"\"\"Upload model and results to Kaggle as a new dataset version.\n    \n    Args:\n        dataset_owner: Owner of the target dataset\n        dataset_slug: Dataset name\n        model_path: Path to model file\n        checkpoint_path: Path to checkpoint file (optional)\n        metrics_path: Path to metrics file (optional)\n        preds_path: Path to predictions file (optional)\n        version_note: Notes for this version\n    \"\"\"\n    api = KaggleApi()\n    api.authenticate()\n\n    # Create zip archive of all files\n    zip_path = \"/kaggle/working/model_upload.zip\"\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        zipf.write(model_path, arcname=os.path.basename(model_path))\n        if checkpoint_path:\n            zipf.write(checkpoint_path, arcname=os.path.basename(checkpoint_path))\n        if metrics_path:\n            zipf.write(metrics_path, arcname=os.path.basename(metrics_path))\n        if preds_path:\n            zipf.write(preds_path, arcname=os.path.basename(preds_path))\n\n    print(f\"Zipped model(s) and metrics to: {zip_path}\")\n\n    # Create metadata file\n    metadata = {\n        \"title\": f\"{dataset_slug} model\",\n        \"id\": f\"{dataset_owner}/{dataset_slug}\",\n        \"licenses\": [{\"name\": \"CC0-1.0\"}]\n    }\n\n    metadata_path = \"/kaggle/working/dataset-metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f, indent=2)\n\n    print(f\"Created metadata file at {metadata_path}\")\n\n    # Upload to Kaggle\n    api.dataset_create_version(\n        folder=\"/kaggle/working\",\n        version_notes=version_note,\n        delete_old_versions=False,\n        convert_to_csv=False\n    )\n    print(f\"Uploaded to Kaggle Dataset: {dataset_owner}/{dataset_slug}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## TTA Transformations","metadata":{}},{"cell_type":"code","source":"def id_fn(x):       # identity\n    return x\n\ndef flip0(x):       # flip depth\n    return torch.flip(x, dims=[2])\n\ndef flip1(x):       # flip height\n    return torch.flip(x, dims=[3])\n\ndef flip2(x):       # flip width\n    return torch.flip(x, dims=[4])\n\ndef rot90_hw(x):    # rotate 90 over H-W (axes 3,4)\n    return torch.rot90(x, k=1, dims=(3, 4))\n\n# Default TTA functions\nDEFAULT_TTA_FNS = [id_fn, flip0, flip1, flip2]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation Pipeline","metadata":{}},{"cell_type":"code","source":"def run_test_and_upload(\n    model,\n    test_ds,\n    loss_fn_dict,\n    thresholds,\n    dataset_owner,\n    dataset_slug,\n    model_path,\n    checkpoint_path=None,\n    version_note=\"\"\n):\n    \"\"\"Run full evaluation pipeline and upload results to Kaggle.\n    \n    Args:\n        model: Model to evaluate\n        test_ds: Test dataset\n        loss_fn_dict: Dictionary of loss functions\n        thresholds: Classification thresholds\n        dataset_owner: Kaggle dataset owner\n        dataset_slug: Kaggle dataset name\n        model_path: Path to model file\n        checkpoint_path: Path to checkpoint file (optional)\n        version_note: Version notes for Kaggle\n        \n    Returns:\n        Test metrics dictionary\n    \"\"\"\n    test_metrics, preds_targets = run_test_evaluation(\n        model=model,\n        test_ds=test_ds,\n        loss_fn_dict=loss_fn_dict,\n        thresholds=thresholds\n    )\n\n    metrics_path, preds_path = save_metrics_and_preds(test_metrics, preds_targets)\n\n    upload_to_kaggle_model(\n        dataset_owner=dataset_owner,\n        dataset_slug=dataset_slug,\n        model_path=model_path,\n        checkpoint_path=checkpoint_path,\n        metrics_path=metrics_path,\n        preds_path=preds_path,\n        version_note=version_note\n    )\n\n    return test_metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_metrics, preds_targets = run_test_evaluation(\n    model=model,\n    test_ds=test_ds,\n    loss_fn_dict=loss_fn_dict,\n    thresholds=custom_thresholds,\n    batch_size=16,\n    num_workers=4,\n    tta_fns=DEFAULT_TTA_FNS\n)\n\n# Save and upload results\nsave_metrics_and_preds(test_metrics, preds_targets, save_dir=\"/kaggle/working\")\nupload_to_kaggle_model(\n    dataset_owner, \n    dataset_slug,\n    \"/kaggle/working/model_best.pth\",\n    checkpoint_path=\"/kaggle/working/checkpoint.pth\",\n    metrics_path='/kaggle/working/test_metrics.json',\n    preds_path='/kaggle/working/preds_targets.json',\n    version_note=\"\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Threshold Optimization","metadata":{}},{"cell_type":"code","source":"def find_best_thresholds_per_class(probs, true_labels, default_class=0, num_thresholds=50):\n    \"\"\"Find the best probability threshold for multi-class classification.\n    \n    Args:\n        probs: numpy array (N_samples, num_classes) - softmax probabilities\n        true_labels: numpy array (N_samples,) - true class labels\n        default_class: Class to assign if no probability exceeds threshold\n        num_thresholds: Number of thresholds to evaluate\n        \n    Returns:\n        Tuple of (best_threshold, best_f1_score)\n    \"\"\"\n    thresholds = np.linspace(0, 1, num_thresholds)\n    best_f1 = -1.0\n    best_threshold = 0.5  # Default fallback threshold\n\n    for thresh in thresholds:\n        preds = []\n        for sample_probs in probs:\n            # Identify classes above threshold\n            above_thresh = sample_probs >= thresh\n            if above_thresh.any():\n                # Select class with max probability among those above threshold\n                pred_class = np.argmax(sample_probs * above_thresh)\n            else:\n                # Fallback to default class\n                pred_class = default_class\n            preds.append(pred_class)\n\n        f1 = f1_score(true_labels, preds, average='macro')\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = thresh\n\n    return best_threshold, best_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Validation Data Collection","metadata":{}},{"cell_type":"code","source":"# Organ index mapping\norgan_indices = {\n    \"bowel\": 0,\n    \"extra\": 1,\n    \"kidney\": 2,\n    \"liver\": 3,\n    \"spleen\": 4,\n}\n\n# Initialize collections for probabilities and labels\nall_probs = defaultdict(list)  # per organ, list of softmax probs arrays\nall_labels = defaultdict(list)  # per organ, list of true labels\n\nmodel.eval()\n\nwith torch.no_grad():\n    for batch in tqdm(val_loader, desc=\"Validation Batches\"):\n        inputs = batch[\"image\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        outputs = model(inputs)\n\n        for organ in outputs.keys():\n            preds = outputs[organ]  # logits tensor\n\n            if preds.shape[-1] == 1:\n                # Binary case: sigmoid probability\n                probs = torch.sigmoid(preds).squeeze(-1).cpu().numpy()\n                # Convert to 2-class format [1-p, p]\n                probs = np.stack([1 - probs, probs], axis=1)\n            else:\n                # Multi-class case: softmax probabilities\n                probs = torch.softmax(preds, dim=1).cpu().numpy()\n\n            all_probs[organ].append(probs)\n            all_labels[organ].append(labels[:, organ_indices[organ]].cpu().numpy())\n\n# Concatenate all batches per organ\nfor organ in all_probs:\n    all_probs[organ] = np.concatenate(all_probs[organ], axis=0)\n    all_labels[organ] = np.concatenate(all_labels[organ], axis=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thresholds = {}\nbest_f1s = {}\n\nfor organ in [\"kidney\", \"liver\", \"spleen\"]:\n    probs = all_probs[organ]  # softmax outputs\n    labels = all_labels[organ]  # true labels\n    thresh, f1 = find_best_thresholds_per_class(probs, labels, default_class=0)\n    best_thresholds[organ] = thresh\n    best_f1s[organ] = f1\n    print(f\"Best threshold for {organ}: {thresh:.2f} with F1: {f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Alternative Threshold Optimization","metadata":{}},{"cell_type":"code","source":"best_thresholds = {}\nmetric = \"f1\"  # Can be \"f1\" or \"accuracy\"\n\nfor organ in all_probs:\n    probs = all_probs[organ]  # shape (N, num_classes)\n    true = all_labels[organ]  # shape (N,)\n    num_classes = probs.shape[1]\n\n    best_thresh = 0.0\n    best_score = 0.0\n\n    # Evaluate thresholds between 0.1 to 0.95\n    thresholds = np.linspace(0.1, 0.95, 18)\n\n    for thresh in thresholds:\n        # Initialize predictions with \"no prediction\" class (-1)\n        pred = np.full_like(true, fill_value=-1)\n\n        # For samples where max probability exceeds threshold, take argmax\n        confident = (probs.max(axis=1) >= thresh)\n        pred[confident] = probs[confident].argmax(axis=1)\n\n        # Skip evaluation if no predictions meet threshold\n        valid_idx = pred != -1\n        if np.sum(valid_idx) == 0:\n            continue\n\n        if metric == \"f1\":\n            score = f1_score(true[valid_idx], pred[valid_idx], average='macro')\n        elif metric == \"accuracy\":\n            score = accuracy_score(true[valid_idx], pred[valid_idx])\n\n        if score > best_score:\n            best_score = score\n            best_thresh = thresh\n\n    best_thresholds[organ] = best_thresh\n    print(f\"[{organ.upper()}] Best {metric}: {best_score:.4f} at threshold: {best_thresh:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction Visualization","metadata":{}},{"cell_type":"code","source":"def plot_random_predictions_all_organs(model, dataset, device, num_samples=5, slice_axis=0, threshold=0.5):\n    \"\"\"Plot random samples with predicted and true labels for all organs.\n    \n    Args:\n        model: Trained model in eval mode\n        dataset: Indexable dataset\n        device: Torch device\n        num_samples: Number of samples to plot\n        slice_axis: Axis for 3D volume slicing (0,1,2)\n        threshold: Classification threshold for binary predictions\n    \"\"\"\n    organ_indices = {\n        \"bowel\": 0,\n        \"extra\": 1,\n        \"kidney\": 2,\n        \"liver\": 3,\n        \"spleen\": 4,\n    }\n    \n    # Label name mappings\n    binary_label_names = {0: \"healthy\", 1: \"injured\"}\n    multiclass_label_names = {\n        \"kidney\": {0: \"healthy\", 1: \"low injury\", 2: \"high injury\"},\n        \"liver\": {0: \"healthy\", 1: \"low injury\", 2: \"high injury\"},\n        \"spleen\": {0: \"healthy\", 1: \"low injury\", 2: \"high injury\"},\n        \"bowel\": binary_label_names,\n        \"extra\": binary_label_names,\n    }\n\n    model.to(device)\n    model.eval()\n\n    # Select random samples\n    indices = random.sample(range(len(dataset)), num_samples)\n\n    # Setup plot grid\n    fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n    if num_samples == 1:\n        axes = np.expand_dims(axes, axis=1)\n\n    with torch.no_grad():\n        for i, idx in enumerate(indices):\n            sample = dataset[idx]\n            img = sample[\"image\"]\n            labels = sample[\"label\"]\n\n            # Prepare model input\n            input_img = img.unsqueeze(0).to(device).float()\n            outputs = model(input_img)\n\n            # Extract middle slice for visualization\n            slices = img.shape[-3:] if img.ndim >= 3 else img.shape\n            mid_slice_idx = slices[slice_axis] // 2\n\n            if img.ndim == 4:\n                if slice_axis == 0:\n                    slice_img = img[:, mid_slice_idx, :, :].cpu().numpy()\n                elif slice_axis == 1:\n                    slice_img = img[:, :, mid_slice_idx, :].cpu().numpy()\n                else:\n                    slice_img = img[:, :, :, mid_slice_idx].cpu().numpy()\n                slice_img = np.moveaxis(slice_img, 0, -1)\n            elif img.ndim == 3:\n                if slice_axis == 0:\n                    slice_img = img[mid_slice_idx, :, :].cpu().numpy()\n                elif slice_axis == 1:\n                    slice_img = img[:, mid_slice_idx, :].cpu().numpy()\n                else:\n                    slice_img = img[:, :, mid_slice_idx].cpu().numpy()\n            else:\n                slice_img = img.cpu().numpy()\n\n            if slice_img.ndim == 3 and slice_img.shape[-1] > 1:\n                slice_img = slice_img[..., 0]\n\n            # Plot image\n            axes[0, i].imshow(slice_img, cmap=\"gray\")\n            axes[0, i].axis(\"off\")\n            axes[0, i].set_title(f\"Sample {idx}\")\n\n            # Generate prediction text\n            text_lines = []\n            for organ, organ_idx in organ_indices.items():\n                pred_tensor = outputs[organ].cpu().squeeze(0)\n                label_names = multiclass_label_names.get(organ, binary_label_names)\n                true_label = labels[organ_idx].item()\n\n                # Determine prediction based on output type\n                if pred_tensor.ndim == 1:\n                    # Multi-class logits\n                    pred_label = torch.argmax(torch.softmax(pred_tensor, dim=0)).item()\n                elif pred_tensor.shape[-1] == 1:\n                    # Binary sigmoid\n                    prob = torch.sigmoid(pred_tensor).item()\n                    pred_label = int(prob >= threshold)\n                elif pred_tensor.shape[-1] == 2:\n                    # Binary softmax\n                    probs = torch.softmax(pred_tensor, dim=-1)\n                    prob = probs[1].item()\n                    pred_label = int(prob >= threshold)\n                else:\n                    # Multi-class softmax\n                    pred_label = torch.argmax(torch.softmax(pred_tensor, dim=-1)).item()\n\n                true_label_str = label_names.get(true_label, str(true_label))\n                pred_label_str = label_names.get(pred_label, str(pred_label))\n                text_lines.append(f\"{organ}:\\n  True: {true_label_str}\\n  Pred: {pred_label_str}\")\n\n            # Add prediction text\n            axes[1, i].axis(\"off\")\n            axes[1, i].text(0, 0.5, \"\\n\\n\".join(text_lines), fontsize=10, va=\"center\", ha=\"left\")\n\n    plt.tight_layout()\n    plt.savefig('/kaggle/working/predictions')\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_random_predictions_all_organs(\n    model=model,\n    dataset=test_ds,\n    device=device,\n    num_samples=5,\n    slice_axis=0,\n    threshold=0.5\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}