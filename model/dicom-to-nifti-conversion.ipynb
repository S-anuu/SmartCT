{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":52254,"databundleVersionId":9674523,"sourceType":"competition"},{"sourceId":12242890,"sourceType":"datasetVersion","datasetId":7713895}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pydicom nibabel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:51.218900Z","iopub.execute_input":"2025-06-25T06:37:51.219241Z","iopub.status.idle":"2025-06-25T06:37:56.311221Z","shell.execute_reply.started":"2025-06-25T06:37:51.219220Z","shell.execute_reply":"2025-06-25T06:37:56.310006Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nfrom pathlib import Path\nimport zipfile\nimport json\nfrom tqdm import tqdm\nimport SimpleITK as sitk\nimport numpy as np\nfrom kaggle.api.kaggle_api_extended import KaggleApi\nimport nibabel as nib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make sure the .config/kaggle directory exists\nos.makedirs(\"/root/.config/kaggle\", exist_ok=True)\n\n# Move kaggle.json to expected directory\nshutil.copy(\"/kaggle/input/kaggle-json/kaggle.json\", \"/root/.config/kaggle/kaggle.json\")\n\n# Set permissions \nos.chmod(\"/root/.config/kaggle/kaggle.json\", 0o600)\n\n# Import and authenticate\nfrom kaggle.api.kaggle_api_extended import KaggleApi\n\napi = KaggleApi()\napi.authenticate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:56.313184Z","iopub.execute_input":"2025-06-25T06:37:56.313704Z","iopub.status.idle":"2025-06-25T06:37:57.001508Z","shell.execute_reply.started":"2025-06-25T06:37:56.313542Z","shell.execute_reply":"2025-06-25T06:37:57.000631Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- CONFIGURATION ---\ndataset_owner = \"\" # kaggle username\ndataset_slug = \"\" # dataset\ndataset_id = f\"{dataset_owner}/{dataset_slug}\"\nmax_batch_size_gb = 12.0 \n\n# Define batch indices for this run (adjust these indices per run)\nstart_idx = 1900 # # 0-54, 54-106\nend_idx =  2000 # next 5 studies (adjust as needed)\nbatch_index = 1  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:57.003583Z","iopub.execute_input":"2025-06-25T06:37:57.004074Z","iopub.status.idle":"2025-06-25T06:37:57.009813Z","shell.execute_reply.started":"2025-06-25T06:37:57.004044Z","shell.execute_reply":"2025-06-25T06:37:57.008783Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Authenticate Kaggle API\napi = KaggleApi()\napi.authenticate()\n\n# Paths\nworking_dir = Path(\"/kaggle/working\")\nnifti_output_dir = working_dir / \"nifti_temp\"\nzip_dir = working_dir / \"nifti_zips\"\nnifti_output_dir.mkdir(exist_ok=True)\nzip_dir.mkdir(exist_ok=True)\n\n# Load the list of DICOM study directories (adjust path as needed)\nwith open(\"/kaggle/input/kaggle-json/study_paths.json\") as f:\n    all_study_dirs = json.load(f)\n\nprint(len(all_study_dirs))\nstudy_dirs = all_study_dirs[start_idx:end_idx]\nprint(len(study_dirs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:57.010873Z","iopub.execute_input":"2025-06-25T06:37:57.011150Z","iopub.status.idle":"2025-06-25T06:37:58.565767Z","shell.execute_reply.started":"2025-06-25T06:37:57.011120Z","shell.execute_reply":"2025-06-25T06:37:58.565002Z"}},"outputs":[{"name":"stdout","text":"4711\n100\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def load_dicom_series(dicom_folder):\n    \"\"\"Load DICOM series with SimpleITK.\"\"\"\n    reader = sitk.ImageSeriesReader()\n    dicom_files = reader.GetGDCMSeriesFileNames(str(dicom_folder))\n    reader.SetFileNames(dicom_files)\n    image = reader.Execute()\n    return image\n\ndef save_compressed_nifti(sitk_image, output_path, compress=True):\n    \"\"\"Save as .nii.gz using NiBabel with proper compression.\"\"\"\n    image_array = sitk.GetArrayFromImage(sitk_image)\n    affine = np.eye(4)  # Replace with correct affine if needed\n    \n    # Create NIfTI image and save\n    nii = nib.Nifti1Image(image_array, affine)\n    \n    # Ensure path ends with .nii.gz for compression\n    if compress and not str(output_path).endswith('.nii.gz'):\n        output_path = str(output_path) + '.nii.gz'\n    \n    nib.save(nii, str(output_path))  # Compression is automatic with .nii.gz suffix\n\n\ndef convert_to_nifti(dicom_folder, output_dir):\n    sitk_image = load_dicom_series(dicom_folder)\n    if sitk_image.GetSize() == (0, 0, 0):\n        return None\n    \n    # Generate filename\n    parts = Path(dicom_folder).parts\n    name = f\"{parts[-2]}_{parts[-1]}.nii.gz\"  # Explicit .nii.gz suffix\n    out_path = output_dir / name\n    \n    save_compressed_nifti(sitk_image, out_path)\n    return out_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:58.566903Z","iopub.execute_input":"2025-06-25T06:37:58.567392Z","iopub.status.idle":"2025-06-25T06:37:58.575887Z","shell.execute_reply.started":"2025-06-25T06:37:58.567364Z","shell.execute_reply":"2025-06-25T06:37:58.574837Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"batch_dir = Path(\"/kaggle/working/nifti_zips\")  # folder that contains batch_*.zip\nmetadata_path = batch_dir / \"dataset-metadata.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:58.576663Z","iopub.execute_input":"2025-06-25T06:37:58.576907Z","iopub.status.idle":"2025-06-25T06:37:58.600615Z","shell.execute_reply.started":"2025-06-25T06:37:58.576888Z","shell.execute_reply":"2025-06-25T06:37:58.599802Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"converted = []\nbatch_size = 0\n\nfor study_path in tqdm(study_dirs):\n    nifti_path = convert_to_nifti(study_path, nifti_output_dir)\n    if nifti_path is None:\n        print(f\"Skipping {study_path} (empty or invalid series)\")\n        continue\n    \n    size_gb = nifti_path.stat().st_size / (1024 ** 3)\n    if batch_size + size_gb > max_batch_size_gb:\n        print(f\"Batch size limit reached ({batch_size:.2f} GB). Creating ZIP and uploading...\")\n        \n        zip_path = zip_dir / f\"batch_{batch_index}.zip\"\n        with zipfile.ZipFile(zip_path, \"w\") as zipf:\n            for f in converted:\n                zipf.write(f, arcname=f.name)\n        print(f\"Created ZIP {zip_path.name}\")\n        \n        # Upload batch to Kaggle\n        api.dataset_create_version(\n            folder=str(zip_dir),\n            version_notes=f\"Upload batch {batch_index} (Studies {start_idx} to {start_idx + len(converted) - 1})\",\n            delete_old_versions=False,\n            convert_to_csv=False,\n        )\n        print(f\"Uploaded batch {batch_index} to Kaggle.\")\n        \n        # Clean up\n        for f in converted:\n            f.unlink()\n        converted = []\n        batch_size = 0\n\n    converted.append(nifti_path)\n    batch_size += size_gb\n\n# Final leftover batch\nif converted:\n    zip_path = zip_dir / f\"batch_{batch_index}.zip\"\n    with zipfile.ZipFile(zip_path, \"w\") as zipf:\n        for f in converted:\n            zipf.write(f, arcname=f.name)\n    print(f\"Created ZIP {zip_path.name}\")\n    \n    # STEP 1: Create metadata file (overwrite if needed)\n    metadata = {\n        \"title\": \"Nifti Data\",\n        \"id\": dataset_id,\n        \"licenses\": [{\"name\": \"CC0-1.0\"}]\n    }\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f, indent=2)\n    \n    # STEP 2: Confirm folder structure\n    print(\"Files in upload folder:\")\n    for f in batch_dir.iterdir():\n        print(\" -\", f.name)\n    \n    # STEP 3: Upload to Kaggle\n    print(f\"\\nUploading to Kaggle dataset: {dataset_id}\")\n    api.dataset_create_version(\n        folder=str(batch_dir),\n        version_notes=\"Added NIfTI zip batch uploads\",\n        delete_old_versions=False,\n        convert_to_csv=False\n    )\n    print(\"Upload complete!\")\n    \nprint(\"All batches processed and uploaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T06:37:58.601634Z","iopub.execute_input":"2025-06-25T06:37:58.601954Z","execution_failed":"2025-06-25T07:50:00.760Z"}},"outputs":[{"name":"stderr","text":"  4%|▍         | 4/100 [02:12<40:33, 25.35s/it]  WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.4/itkImageSeriesReader.hxx, line 478\nImageSeriesReader (0x10900d70): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000994872\n\n  8%|▊         | 8/100 [03:26<30:36, 19.96s/it]WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.4/itkImageSeriesReader.hxx, line 478\nImageSeriesReader (0x10900d70): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000696162\n\n 19%|█▉        | 19/100 [08:26<27:37, 20.46s/it]  WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.4/itkImageSeriesReader.hxx, line 478\nImageSeriesReader (0x10900d70): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000998117\n\n 73%|███████▎  | 73/100 [29:00<14:39, 32.56s/it]WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.4/itkImageSeriesReader.hxx, line 478\nImageSeriesReader (0x10900d70): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000576884\n\n 76%|███████▌  | 76/100 [29:57<09:10, 22.93s/it]","output_type":"stream"}],"execution_count":null}]}